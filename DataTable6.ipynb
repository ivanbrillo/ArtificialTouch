{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FEATURE EXTRACTION",
   "id": "70191282af507847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the data frames and save them if needed\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from CreateTable import create_df\n",
    "df1 = create_df(\"Dataset/DamasconeA/data2/*_CPXE_*.csv\", offset=(49, 51), angle=1)\n",
    "df2 = create_df(\"Dataset/DamasconeA/data1/*_CPXE_*.csv\")\n",
    "df3 = create_df(\"Dataset/DamasconeB/together/*_CPXE_*.csv\")\n",
    "\n",
    "df1.to_pickle(\"Dataset/DamasconeA2.pkl\")\n",
    "df2.to_pickle(\"Dataset/DamasconeA.pkl\")\n",
    "df3.to_pickle(\"Dataset/DamasconeB.pkl\")"
   ],
   "id": "ff0f43a9b9d8e1f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:42:25.799479Z",
     "start_time": "2025-04-30T10:41:50.498810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_pickle(\"Dataset/DamasconeA2.pkl\")\n",
    "data_validation = pd.read_pickle(\"Dataset/DamasconeA.pkl\")\n",
    "data_test = pd.read_pickle(\"Dataset/DamasconeB.pkl\")\n",
    "\n",
    "# TODO nan (interpolate?)\n",
    "# TODO highest in the center"
   ],
   "id": "8521e62c79249487",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:42:41.223641Z",
     "start_time": "2025-04-30T10:42:41.185676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data_train['stiffness_to_relaxation'] = data_train['Stiffness'] / data_train['force_relaxation']\n",
    "data_train['oscillation_to_max_force'] = data_train['force_oscillation'] / data_train['force_max']\n",
    "\n",
    "data_test['stiffness_to_relaxation'] = data_test['Stiffness'] / data_test['force_relaxation']\n",
    "data_test['oscillation_to_max_force'] = data_test['force_oscillation'] / data_test['force_max']\n",
    "\n",
    "data_validation['stiffness_to_relaxation'] = data_validation['Stiffness'] / data_validation['force_relaxation']\n",
    "data_validation['oscillation_to_max_force'] = data_validation['force_oscillation'] / data_validation['force_max']\n"
   ],
   "id": "38dc38f85ffa1939",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_train = data_train.dropna()\n",
    "data_test = data_test.dropna()\n",
    "data_validation = data_validation.dropna()"
   ],
   "id": "91edb4ce000552bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:42:43.351790Z",
     "start_time": "2025-04-30T10:42:43.315656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helper import feature_list2, feature_list_all\n",
    "to_remove = ['poly3_coef0', 'poly3_coef1', 'poly3_coef2', 'poly3_coef3',\n",
    "             'poly4_coef0', 'poly4_coef1', 'poly4_coef2', 'poly4_coef3', 'poly4_coef4',\n",
    "             'poly5_coef0', 'poly5_coef1', 'poly5_coef2', 'poly5_coef3', 'poly5_coef4',\n",
    "             # Segmentation features\n",
    "             'segment2_slope', 'segment3_slope', 'segment2_force_std', 'segment3_force_std',\n",
    "             'segment2_skew', 'segment3_skew',\n",
    "             'Power', \"Dominant Frequency\", \"stiffness_ratio\",\"max_pos_rate\",\n",
    "             \"loading_energy\", \"jerk_max\", \"zero_crossings_force\", \"loading_unloading_area_ratio\", \"force_ratio_75_25\",\n",
    "             \"zero_crossings_position\",\"damping_coefficient\", \"spectral_centroid_force\",\"spectral_centroid_position\", \"impedance_ratio_lowfreq\",\n",
    "             \"coherence_LF\", \"coherence_HF\", \"elastic_coeff\", 'local_std_Stiffness', 'local_skewness_Stiffness', 'local_kurtosis_Stiffness',\n",
    "             'local_range_Stiffness', 'local_std_Upstroke', 'local_skewness_Upstroke', 'local_kurtosis_Upstroke',\n",
    "             'local_skewness_Tau', 'local_kurtosis_Tau', 'local_mean_time_to_max', 'local_std_time_to_max', 'local_skewness_time_to_max', 'local_kurtosis_time_to_max', 'local_range_time_to_max',\n",
    "             \"local_gradient_norm_stiffness\", \"stiffness_deviation_from_global\", \"position_deviation_from_global\",\"position_deviation_from_global_median\",\"Downstroke1\", \"position_deviation_from_global_median\",\n",
    "             \"position_z_score\", \"lbp_code_P8_R1\", \"lbp_code_P16_R2\",\n",
    "             \"lbp_bin1_P8_R1\", \"lbp_bin2_P8_R1\", \"lbp_bin3_P8_R1\",\n",
    "             \"lbp_val1_P8_R1\", \"lbp_val2_P8_R1\", \"lbp_val3_P8_R1\",\n",
    "             \"lbp_bin1_P16_R2\", \"lbp_bin2_P16_R2\", \"lbp_bin3_P16_R2\",\n",
    "             \"lbp_val1_P16_R2\", \"lbp_val2_P16_R2\", \"lbp_val3_P16_R2\",\n",
    "             \"lbp_entropy_P8_R1\", \"lbp_entropy_P16_R2\", \"local_Ra_w3\", \"local_Rq_w3\", \"local_skewness_w3\", \"local_kurtosis_w3\",\n",
    "             \"local_peak_height_w3\", \"local_valley_depth_w3\", \"local_stiffness_w3\", \"local_stiffness_zscore_w3\",\n",
    "             \"local_Ra_w5\", \"local_Rq_w5\", \"local_skewness_w5\", \"local_kurtosis_w5\",\n",
    "             \"local_peak_height_w5\", \"local_valley_depth_w5\",\"local_Ra_w3\", \"local_Rq_w3\", \"local_skewness_w3\", \"local_kurtosis_w3\",\n",
    "             \"local_peak_height_w3\", \"local_valley_depth_w3\", \"local_stiffness_zscore_w3\",\n",
    "             \"local_Ra_w5\", \"local_Rq_w5\", \"local_skewness_w5\", \"local_kurtosis_w5\",\n",
    "             \"local_peak_height_w5\", \"local_valley_depth_w5\", \"local_stiffness_zscore_w5\",\n",
    "             \"local_Ra_w7\", \"local_Rq_w7\", \"local_skewness_w7\", \"local_kurtosis_w7\",\n",
    "             \"local_peak_height_w7\", \"local_valley_depth_w7\", \"local_stiffness_zscore_w7\",\n",
    "             \"stiffness_harris_response\", \"stiffness_edge_response\",\n",
    "             \"surface_mean_curvature\", \"surface_gaussian_curvature\", \"surface_type\",\"local_range_Upstroke\",\n",
    "             'local_range_Upstroke', 'local_mean_Downstroke1', 'local_std_Downstroke1', 'local_skewness_Downstroke1', 'local_kurtosis_Downstroke1',\n",
    "             'local_range_Downstroke1','local_skewness_Downstroke2', 'local_kurtosis_Downstroke2']\n",
    "#feature_list_3 = feature_list = [x for x in feature_list2 + ['stiffness_to_relaxation', 'oscillation_to_max_force'] if x not in to_remove]\n",
    "\n",
    "feature_list = [x for x in feature_list_all if x not in to_remove]\n",
    "\n",
    "# feature_list = feature_list_3\n",
    "# feature_list = ['loading_unloading_area_ratio', 'peak_width', 'stiffness_to_relaxation', 'Stiffness']\n",
    "# feature_list = [\"Stiffness\", \"Upstroke\", \"Downstroke\", \"P_ss\"] #, \"P_ss\", \"loading_energy\"]peak_position\n",
    "\n",
    "# feature_list = ['poly4_coef4', 'poly4_coef3', 'poly5_coef0', 'loading_unloading_area_ratio', 'Stiffness', 'quartic_coefficient', 'Upstroke']"
   ],
   "id": "60ea06290a3d387b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VISUALIZATION OF FEATURE",
   "id": "a58529e67a87e668"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_features_singledf\n",
    "print(\"DATA TRAIN\")\n",
    "plot_features_singledf(data_train, feature_list=feature_list)"
   ],
   "id": "5cee189636e85ff1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"DATA VALIDATION\")\n",
    "plot_features_singledf(data_validation, feature_list=feature_list)"
   ],
   "id": "7628c89a07c7e29f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"DATA TEST\")\n",
    "plot_features_singledf(data_test, feature_list=feature_list)"
   ],
   "id": "c5a85386c4a38675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPATIAL SMOOTHING",
   "id": "17ad70bb5a386364"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:47:00.839929Z",
     "start_time": "2025-04-30T10:42:47.524059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.interpolate import NearestNDInterpolator\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "from helper import *\n",
    "\n",
    "smoothing_config = {\n",
    "    'Entropy': 'gaussian',\n",
    "}  # Dictionary 'feature-name' : type of smoothing (set if you want to test other method of smoothing instead of median)\n",
    "\n",
    "\n",
    "def apply_smoothing(grid_z, method='median'):\n",
    "    if method == 'median':\n",
    "        return median_filter(grid_z, size=3, mode='reflect')\n",
    "    elif method == 'gaussian':\n",
    "        return gaussian_filter(grid_z, sigma=2)\n",
    "    elif method == 'diffusion':\n",
    "        # Simple anisotropic diffusion\n",
    "        def diffusion_step(img, kappa=50):\n",
    "            # Compute image gradients\n",
    "            dy, dx = np.gradient(img)\n",
    "\n",
    "            # Compute diffusion coefficients\n",
    "            diff_coef_x = 1 / (1 + (dx / kappa) ** 2)\n",
    "            diff_coef_y = 1 / (1 + (dy / kappa) ** 2)\n",
    "\n",
    "            # Compute diffusion\n",
    "            diff_x = np.zeros_like(img)\n",
    "            diff_y = np.zeros_like(img)\n",
    "\n",
    "            diff_x[1:-1, 1:-1] = diff_coef_x[1:-1, 1:-1] * (img[1:-1, 2:] - img[1:-1, 1:-1])\n",
    "            diff_y[1:-1, 1:-1] = diff_coef_y[1:-1, 1:-1] * (img[2:, 1:-1] - img[1:-1, 1:-1])\n",
    "\n",
    "            return img + 0.25 * (diff_x + diff_y)\n",
    "\n",
    "        # Apply multiple diffusion steps\n",
    "        iterations = 20\n",
    "        img = grid_z.copy()\n",
    "        for i in range(iterations):\n",
    "            img = diffusion_step(img)\n",
    "        return img\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Smoothing method not implemented: {method}\")\n",
    "\n",
    "\n",
    "def get_grid_bounds(df):\n",
    "    x_min, x_max = int(df[\"posx\"].min()), int(df[\"posx\"].max())\n",
    "    y_min, y_max = int(df[\"posy\"].min()), int(df[\"posy\"].max())\n",
    "    grid_shape = (y_max - y_min + 1, x_max - x_min + 1)\n",
    "    return x_min, y_min, grid_shape\n",
    "\n",
    "\n",
    "# Smoothing function for a single dataframe\n",
    "def smooth_subset(subset_df, x_min, y_min, grid_shape):\n",
    "    smoothed_subset = pd.DataFrame(index=subset_df.index)\n",
    "\n",
    "    for feature in feature_list:\n",
    "        # Initialize grid with NaNs\n",
    "        grid_z = np.full(grid_shape, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Map each data point to the grid\n",
    "        for _, row in subset_df.iterrows():\n",
    "            x_idx = int(row[\"posx\"]) - x_min\n",
    "            y_idx = int(row[\"posy\"]) - y_min\n",
    "            grid_z[y_idx, x_idx] = row[feature]\n",
    "\n",
    "        # Interpolate missing values\n",
    "        yy, xx = np.indices(grid_z.shape)\n",
    "        valid_mask = ~np.isnan(grid_z)\n",
    "\n",
    "        if np.any(~valid_mask):\n",
    "            interpolator = NearestNDInterpolator(\n",
    "                np.column_stack((yy[valid_mask], xx[valid_mask])),\n",
    "                grid_z[valid_mask]\n",
    "            )\n",
    "            grid_z = interpolator(yy, xx)\n",
    "\n",
    "        # Apply feature-specific smoothing\n",
    "        methods = smoothing_config.get(feature,\n",
    "                                       'median')  # Get the designed methods, if None select defaul 'median' method\n",
    "        if isinstance(methods, list):\n",
    "            for method in methods:\n",
    "                grid_z = apply_smoothing(grid_z, method=method)\n",
    "        else:\n",
    "            grid_z = apply_smoothing(grid_z, method=methods)\n",
    "\n",
    "        # Map smoothed grid back to DataFrame\n",
    "        smoothed_subset[feature] = [\n",
    "            grid_z[int(row[\"posy\"]) - y_min, int(row[\"posx\"]) - x_min]\n",
    "            for _, row in subset_df.iterrows()\n",
    "        ]\n",
    "\n",
    "    # Add back metadata columns\n",
    "    smoothed_subset[['label', 'posx', 'posy']] = subset_df[['label', 'posx', 'posy']]\n",
    "    return smoothed_subset\n",
    "\n",
    "\n",
    "if smoothing_config is None:\n",
    "    smoothing_config = {feature: 'median' for feature in feature_list}\n",
    "\n",
    "# Compute grid bounds and smooth each subset\n",
    "test_x_min, test_y_min, test_grid_shape = get_grid_bounds(data_test)\n",
    "train_x_min, train_y_min, train_grid_shape = get_grid_bounds(data_train)\n",
    "val_x_min, val_y_min, val_grid_shape = get_grid_bounds(data_validation)\n",
    "\n",
    "# Smooth each subset SEPARATELY\n",
    "smoothed_test = smooth_subset(data_test, test_x_min, test_y_min, test_grid_shape)\n",
    "smoothed_train = smooth_subset(data_train, train_x_min, train_y_min, train_grid_shape)\n",
    "smoothed_validation = smooth_subset(data_validation, val_x_min, val_y_min, val_grid_shape)\n",
    "\n",
    "smoothed_df = pd.concat([smoothed_test, smoothed_train],ignore_index=True)  # For visualization in the next sections only"
   ],
   "id": "99d148d49061a836",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DB SPLITTING",
   "id": "4b301ca0f0f71e01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Binary Classifier",
   "id": "25ce08865461ab20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "# Display class distribution\n",
    "X = smoothed_df[feature_list + [\"posx\", \"posy\"]]\n",
    "y = smoothed_df['label']\n",
    "\n",
    "# train_df = pd.concat([train_df1, train_df2], ignore_index=True)\n",
    "# smoothed_train = pd.concat([smoothed_train1, smoothed_train2], ignore_index=True)\n",
    "\n",
    "# Training distribution:\n",
    "class_distribution = Counter(smoothed_train['label'])\n",
    "print(\"Class distribution in the dataset:\")\n",
    "for label, count in sorted(class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y) * 100:.2f}%)\")\n",
    "\n",
    "# Test distribution:\n",
    "class_distribution = Counter(smoothed_test['label'])\n",
    "print(\"Class distribution in the dataset:\")\n",
    "for label, count in sorted(class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y) * 100:.2f}%)\")\n",
    "\n",
    "# Prepare data for classification\n",
    "X_train = smoothed_train[feature_list + [\"posx\", \"posy\"]]\n",
    "y_train = smoothed_train['label']\n",
    "\n",
    "X_test = smoothed_test[feature_list + [\"posx\", \"posy\"]]\n",
    "y_test = smoothed_test['label']\n",
    "\n",
    "X_validation = smoothed_validation[feature_list + [\"posx\", \"posy\"]]\n",
    "y_validation = smoothed_validation['label']\n",
    "\n",
    "# Create the figure and axes: 2 rows (train/test), then 3 histograms\n",
    "fig, axs = plt.subplots(2, 4, figsize=(22, 14), gridspec_kw={'width_ratios': [3, 1, 1, 1]})\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create consistent color map using turbo\n",
    "unique_labels = sorted(data_train['label'].unique())  # or union of train + test if needed\n",
    "palette_colors = sns.color_palette(\"turbo\", n_colors=len(unique_labels))\n",
    "label_color_dict = {label: color for label, color in zip(unique_labels, palette_colors)}\n",
    "\n",
    "# Plot train\n",
    "sns.scatterplot(\n",
    "    data=data_train,\n",
    "    x='posx',\n",
    "    y='posy',\n",
    "    hue='label',\n",
    "    palette=label_color_dict,  # Use fixed mapping\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_title(\"Train Set Distribution (posx vs posy)\")\n",
    "axs[0, 0].set_xlabel(\"Position X (posx)\")\n",
    "axs[0, 0].set_ylabel(\"Position Y (posy)\")\n",
    "axs[0, 0].legend(title='Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot test with same label-color mapping\n",
    "sns.scatterplot(\n",
    "    data=data_test,\n",
    "    x='posx',\n",
    "    y='posy',\n",
    "    hue='label',\n",
    "    palette=label_color_dict,  # Same dictionary ensures color consistency\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_title(\"Test Set Distribution (posx vs posy)\")\n",
    "axs[1, 0].set_xlabel(\"Position X (posx)\")\n",
    "axs[1, 0].set_ylabel(\"Position Y (posy)\")\n",
    "axs[1, 0].legend(title='Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# --- Histograms / Class Distribution Plots ---\n",
    "plot_class_distribution(smoothed_df['label'], axs[0, 1], \"Class Dist. (Entire)\")\n",
    "plot_class_distribution(y_train, axs[0, 2], \"Class Dist. (Train)\")\n",
    "plot_class_distribution(y_test, axs[0, 3], \"Class Dist. (Test)\")\n",
    "\n",
    "# Hide the unused bottom row histograms\n",
    "for ax in axs[1, 1:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # Drop posx and posy columns from the training and testing sets after plotting\n",
    "# X_train = X_train.drop(columns=['posx', 'posy'])\n",
    "# X_test = X_test.drop(columns=['posx', 'posy'])"
   ],
   "id": "934212b578e97c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_train1 = StandardScaler()\n",
    "scaler_train2 = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "X_train_selected = X_train[feature_list]\n",
    "X_test_selected = X_test[feature_list]\n",
    "X_validation_selected = X_validation[feature_list]\n",
    "\n",
    "# X_train_selected_1 = X_train_selected[X_train[\"posy\"] <= 140]\n",
    "# X_train_selected_2 = X_train_selected[X_train[\"posy\"] > 140]\n",
    "\n",
    "X_train_scaled = scaler_train1.fit_transform(X_train_selected)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_list, index=X_train_selected.index)\n",
    "\n",
    "X_validation_scaled = scaler_train1.fit_transform(X_validation_selected)\n",
    "X_validation_scaled = pd.DataFrame(X_validation_scaled, columns=feature_list, index=X_validation_selected.index)\n",
    "\n",
    "# X_train_scaled2 = scaler_train2.fit_transform(X_train_selected_2)\n",
    "\n",
    "# X_train_scaled1 = pd.DataFrame(X_train_scaled1, columns=feature_list, index=X_train_selected_1.index)\n",
    "# X_train_scaled2 = pd.DataFrame(X_train_scaled2, columns=feature_list, index=X_train_selected_2.index)\n",
    "# X_train_scaled = pd.concat([X_train_scaled1, X_train_scaled2]).sort_index()\n",
    "\n",
    "X_test_scaled = scaler_test.fit_transform(X_test_selected)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_list, index=X_test_selected.index)"
   ],
   "id": "9b855847b244c914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance, ks_2samp\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def calculate_mutual_info(X_data, y_data, feature_list, random_state=42):\n",
    "    \"\"\"Calculate mutual information scores for features.\"\"\"\n",
    "    return mutual_info_classif(X_data[feature_list], y_data, random_state=random_state)\n",
    "\n",
    "\n",
    "def calculate_wasserstein_distances(train_data, validation_data, feature_list):\n",
    "    \"\"\"Calculate Wasserstein distance between train and validation for each feature.\"\"\"\n",
    "    distances = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        distance = wasserstein_distance(train_data[feature], validation_data[feature])\n",
    "        distances.append({'feature': feature, 'wasserstein_distance': distance})\n",
    "\n",
    "    return pd.DataFrame(distances)\n",
    "\n",
    "\n",
    "def calculate_distribution_metrics(train_data, validation_data, feature_list):\n",
    "    \"\"\"Calculate distribution metrics between train and validation sets.\"\"\"\n",
    "    metrics = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        # Wasserstein distance (Earth Mover's Distance)\n",
    "        w_distance = wasserstein_distance(train_data[feature], validation_data[feature])\n",
    "\n",
    "        # Kolmogorov-Smirnov test\n",
    "        ks_stat, ks_pval = ks_2samp(train_data[feature], validation_data[feature])\n",
    "\n",
    "        metrics.append({\n",
    "            'feature': feature,\n",
    "            'wasserstein_distance': w_distance,\n",
    "            'ks_statistic': ks_stat,\n",
    "            'ks_pvalue': ks_pval\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "def calculate_class_distribution_metrics(X_train, y_train, X_validation, y_validation, feature_list, selected_classes):\n",
    "    \"\"\"Calculate distribution metrics for each selected class.\"\"\"\n",
    "    class_metrics = {}\n",
    "\n",
    "    for cls in selected_classes:\n",
    "        # Filter data for this class\n",
    "        X_train_cls = X_train[y_train == cls]\n",
    "        X_val_cls = X_validation[y_validation == cls]\n",
    "\n",
    "        # Calculate metrics for this class\n",
    "        metrics_df = calculate_distribution_metrics(X_train_cls, X_val_cls, feature_list)\n",
    "        class_metrics[cls] = metrics_df\n",
    "\n",
    "    return class_metrics\n",
    "\n",
    "\n",
    "def plot_feature_importance(mi_df, metrics_df, figsize=(24, 12)):\n",
    "    \"\"\"Plot mutual information and distribution metrics for features.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "\n",
    "    # Ensure both dataframes have the same feature ordering\n",
    "    mi_df = mi_df.sort_values('smoothed', ascending=False)\n",
    "\n",
    "    # Merge to maintain the same order\n",
    "    merged_df = mi_df[['feature']].merge(metrics_df, on='feature')\n",
    "\n",
    "    # Plot Mutual Information\n",
    "    sns.barplot(x='smoothed', y='feature', data=mi_df.head(15),\n",
    "                color='blue', alpha=0.7, ax=axes[0, 0])\n",
    "    sns.barplot(x='test', y='feature', data=mi_df.head(15),\n",
    "                color='green', alpha=0.7, ax=axes[0, 1])\n",
    "\n",
    "    axes[0, 0].set_title('Mutual Information (Train)', fontsize=14)\n",
    "    axes[0, 1].set_title('Mutual Information (Validation)', fontsize=14)\n",
    "\n",
    "    # Plot Wasserstein Distance only\n",
    "    sns.barplot(x='wasserstein_distance', y='feature', data=merged_df.head(15),\n",
    "                palette='mako', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Wasserstein Distance (Train vs Validation)', fontsize=14)\n",
    "\n",
    "    # Turn off the unused subplot\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualize_feature_distributions(X_train, y_train, X_validation, y_validation,\n",
    "                                    selected_features, selected_classes):\n",
    "    figsize = (3 * len(selected_classes), 3 * len(selected_features))\n",
    "    fig, axes = plt.subplots(len(selected_features), len(selected_classes), figsize=figsize)\n",
    "\n",
    "    for i, feature in enumerate(selected_features):\n",
    "        for j, cls in enumerate(selected_classes):\n",
    "            ax = axes[i, j] if len(selected_features) > 1 else axes[j]\n",
    "\n",
    "            # Filter data for the class\n",
    "            train_data = X_train[y_train == cls][feature]\n",
    "            val_data = X_validation[y_validation == cls][feature]\n",
    "\n",
    "            # Plot distributions\n",
    "            sns.histplot(train_data, kde=True, color='blue', alpha=0.5,\n",
    "                         ax=ax, label='Train', stat='density')\n",
    "            sns.histplot(val_data, kde=True, color='green', alpha=0.5,\n",
    "                         ax=ax, label='Validation', stat='density')\n",
    "\n",
    "            # Calculate Wasserstein distance for this feature and class\n",
    "            w_dist = wasserstein_distance(train_data, val_data)\n",
    "\n",
    "            ax.set_title(f\"Class {cls}, Feature: {feature}\\nWasserstein = {w_dist:.4f}\", fontsize=10)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.legend()\n",
    "\n",
    "            if i == len(selected_features) - 1:\n",
    "                ax.set_xlabel(feature)\n",
    "            else:\n",
    "                ax.set_xlabel('')\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_ylabel('Density')\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def select_features_advanced(mi_df, metrics_df, class_metrics, selected_classes,\n",
    "                             mi_threshold=0.5, wasserstein_threshold=0.12,\n",
    "                             class_wasserstein_threshold=None):\n",
    "    \"\"\"\n",
    "    Select features based on multiple criteria:\n",
    "    1. High mutual information in both train and validation\n",
    "    2. Low overall distribution distances between train and validation\n",
    "    3. Low per-class distribution distances\n",
    "    \"\"\"\n",
    "    # Step 1: Filter by mutual information\n",
    "    mi_selected = mi_df[(mi_df['smoothed'] > mi_threshold) &\n",
    "                        (mi_df['test'] > mi_threshold)]\n",
    "\n",
    "    # Step 2: Filter by overall distribution metrics\n",
    "    dist_selected = metrics_df[metrics_df['wasserstein_distance'] < wasserstein_threshold]\n",
    "\n",
    "    # Combine the filters\n",
    "    combined = mi_selected[['feature']].merge(dist_selected[['feature']], on='feature')\n",
    "    combined_features = combined['feature'].tolist()\n",
    "\n",
    "    # Step 3: Filter by per-class distribution metrics\n",
    "    if class_wasserstein_threshold is not None:\n",
    "        final_features = []\n",
    "        for feature in combined_features:\n",
    "            ok = True\n",
    "            for cls in selected_classes:\n",
    "                cls_df = class_metrics[cls]\n",
    "                w_dist = cls_df.loc[cls_df['feature'] == feature, 'wasserstein_distance'].values[0]\n",
    "                if w_dist > class_wasserstein_threshold:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok:\n",
    "                final_features.append(feature)\n",
    "    else:\n",
    "        final_features = combined_features\n",
    "\n",
    "    return final_features\n",
    "\n",
    "\n",
    "def find_best_features(X_train_scaled, y_train, X_validation_scaled, y_validation, feature_list,\n",
    "                       selected_classes, mi_threshold=0.5, wasserstein_threshold=0.1,\n",
    "                       class_wasserstein_threshold=None, plot=False):\n",
    "    \"\"\"Enhanced main function to perform feature selection analysis with per-class threshold.\"\"\"\n",
    "    # Filter data for selected classes\n",
    "    train_mask = y_train.isin(selected_classes)\n",
    "    X_train_filtered = X_train_scaled[train_mask]\n",
    "    y_train_filtered = y_train[train_mask]\n",
    "\n",
    "    test_mask = y_validation.isin(selected_classes)\n",
    "    X_val_filtered = X_validation_scaled[test_mask]\n",
    "    y_val_filtered = y_validation[test_mask]\n",
    "\n",
    "    # Calculate mutual information for train and validation sets\n",
    "    mi_scores_train = calculate_mutual_info(X_train_filtered, y_train_filtered, feature_list)\n",
    "    mi_scores_val = calculate_mutual_info(X_val_filtered, y_val_filtered, feature_list)\n",
    "\n",
    "    mi_df = pd.DataFrame({\n",
    "        'feature': feature_list,\n",
    "        'smoothed': mi_scores_train,\n",
    "        'test': mi_scores_val,\n",
    "    })\n",
    "\n",
    "    # Calculate overall distribution metrics\n",
    "    metrics_df = calculate_distribution_metrics(X_train_filtered, X_val_filtered, feature_list)\n",
    "\n",
    "    # Calculate class-specific distribution metrics\n",
    "    class_metrics = calculate_class_distribution_metrics(\n",
    "        X_train_filtered, y_train_filtered,\n",
    "        X_val_filtered, y_val_filtered,\n",
    "        feature_list, selected_classes\n",
    "    )\n",
    "\n",
    "    # Select features based on enhanced criteria\n",
    "    selected_features = select_features_advanced(\n",
    "        mi_df, metrics_df, class_metrics, selected_classes,\n",
    "        mi_threshold, wasserstein_threshold,\n",
    "        class_wasserstein_threshold\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        print(\"Plotting overall feature importance...\")\n",
    "        plot_feature_importance(mi_df, metrics_df)\n",
    "        plt.show()\n",
    "\n",
    "        if len(selected_features) > 0:\n",
    "            visualize_feature_distributions(\n",
    "                X_train_filtered, y_train_filtered,\n",
    "                X_val_filtered, y_val_filtered,\n",
    "                selected_features, selected_classes\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"\\n Selected Features ({len(selected_features)}):\")\n",
    "        print(f\"  - MI threshold: {mi_threshold}\")\n",
    "        print(f\"  - Wasserstein threshold: {wasserstein_threshold}\")\n",
    "        if class_wasserstein_threshold is not None:\n",
    "            print(f\"  - Per-class Wasserstein threshold: {class_wasserstein_threshold}\")\n",
    "\n",
    "        if len(selected_features) > 0:\n",
    "            for i, feature in enumerate(selected_features, 1):\n",
    "                print(f\"  {i}. {feature}\")\n",
    "        else:\n",
    "            print(\"  No features met all criteria. Consider relaxing thresholds.\")\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "selected_features = find_best_features(\n",
    "    X_train_scaled=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_validation_scaled=X_validation_scaled,\n",
    "    y_validation=y_validation,\n",
    "    feature_list=feature_list,\n",
    "    selected_classes=[2, 3, 4, 5],\n",
    "    mi_threshold=0.3,\n",
    "    wasserstein_threshold=0.275,\n",
    "    class_wasserstein_threshold=0.2,\n",
    "    plot=True\n",
    ")\n"
   ],
   "id": "72a9785e93e73c38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def find_best_smoothing_params(\n",
    "        df,\n",
    "        features_to_smooth,\n",
    "        class_label_col,\n",
    "        bandwidth_values,\n",
    "        center_emphasis_values,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each (bw,ce) in the grid, smooth the df, then compute\n",
    "    silhouette_score on the smoothed feature matrix (only the smoothed\n",
    "    features), using the true class labels in `class_label_col`.\n",
    "    Returns a DataFrame of scores and the best (bw, ce).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    true_labels = df[class_label_col].values\n",
    "\n",
    "    for bw in tqdm(bandwidth_values, desc=\"bandwidth\"):\n",
    "        for ce in center_emphasis_values:\n",
    "            # 1) smooth\n",
    "            selected_features = find_best_features(\n",
    "                X_train_scaled=X_train_scaled,\n",
    "                y_train=y_train,\n",
    "                X_validation_scaled=X_validation_scaled,\n",
    "                y_validation=y_validation,\n",
    "                feature_list=feature_list,\n",
    "                selected_classes=[2, 3, 4, 5],\n",
    "                mi_threshold=0.3,\n",
    "                wasserstein_threshold=bw,\n",
    "                class_wasserstein_threshold=ce\n",
    "            )\n",
    "\n",
    "            X = df[selected_features].values\n",
    "\n",
    "            try:\n",
    "                score = silhouette_score(X, true_labels)\n",
    "            except ValueError:\n",
    "                score = np.nan\n",
    "\n",
    "            results.append({\n",
    "                'w_th': bw,\n",
    "                'cw_th': ce,\n",
    "                'n_features': len(selected_features),\n",
    "                'features': selected_features,\n",
    "                'silhouette': score\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # pick the best\n",
    "    best = results_df.loc[results_df['silhouette'].idxmax()]\n",
    "    return results_df, best['w_th'], best['cw_th'], best['silhouette']\n",
    "\n",
    "\n",
    "bw_vals = np.arange(0, 0.15, 0.025).tolist()\n",
    "ce_vals = np.arange(0, 0.2, 0.025).tolist()\n",
    "features = [f for f in feature_list if f not in ['posx', 'posy', 'label', 'class']]\n",
    "\n",
    "df_all = pd.concat([X_train_scaled, X_validation_scaled], axis=0, ignore_index=True)\n",
    "df_all['class'] = pd.concat([y_train, y_validation], axis=0, ignore_index=True)\n",
    "\n",
    "results_df, best_bw, best_ce, best_score = find_best_smoothing_params(\n",
    "    df=df_all,\n",
    "    features_to_smooth=features,\n",
    "    class_label_col='class',\n",
    "    bandwidth_values=bw_vals,\n",
    "    center_emphasis_values=ce_vals\n",
    ")\n",
    "\n",
    "print(\"Best params:\", best_bw, best_ce, \". silhouette:\", best_score)\n",
    "results_df = results_df.dropna()\n",
    "\n",
    "# keeps the best silhouette score for equal number of features\n",
    "results_df = results_df.loc[results_df.groupby('n_features')['silhouette'].idxmax()].reset_index(drop=True)\n",
    "results_df = results_df[results_df[\"silhouette\"] > 0]\n",
    "results_df"
   ],
   "id": "fb258a23a944670d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from trainer import *\n",
    "\n",
    "models = [\n",
    "    ('SVM', SVC(kernel='rbf', C=0.5, gamma='scale', probability=True, random_state=42)),  # n_jobs not supported\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=8, metric='minkowski', p=2, n_jobs=-1)),\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),  # no n_jobs\n",
    "]\n",
    "\n",
    "for features_set in results_df[\"features\"].tolist():\n",
    "    X_train_selected = X_train_scaled[features_set]\n",
    "    X_test_selected = X_test_scaled[features_set]\n",
    "    X_validation_selected = X_validation_scaled[features_set]\n",
    "\n",
    "    # Convert labels to binary classification (0 vs all)\n",
    "    y_train_binary = np.where(y_train == 0, 0, 1)\n",
    "    y_test_binary = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "    # Apply ADASYN for class imbalance handling\n",
    "    adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=10)\n",
    "    X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train_binary)\n",
    "\n",
    "    results = fit_and_evaluate_models(models, X_train_adasyn, y_train_adasyn, X_test_selected, y_test_binary)\n",
    "    plot_model_comparison(results)\n",
    "    print(\"\\n\\n\")"
   ],
   "id": "27454b564d6e49f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_features\n",
    "\n",
    "X_train_nz = X_train_scaled.copy()\n",
    "X_train_nz[\"label\"] = y_train\n",
    "X_train_nz[\"posy\"] = X_train[\"posy\"]\n",
    "X_train_nz[\"posx\"] = X_train[\"posx\"]\n",
    "\n",
    "X_test_new_nz = X_test_scaled.copy()\n",
    "X_test_new_nz[\"label\"] = y_test\n",
    "X_test_new_nz[\"posx\"] = X_test[\"posx\"]\n",
    "X_test_new_nz[\"posy\"] = X_test[\"posy\"]\n",
    "\n",
    "X_val_new_nz = X_validation_scaled.copy()\n",
    "X_val_new_nz[\"label\"] = y_validation\n",
    "X_val_new_nz[\"posx\"] = X_validation[\"posx\"]\n",
    "X_val_new_nz[\"posy\"] = X_validation[\"posy\"]\n",
    "\n",
    "# plot_features(X_train_nz, X_test_new_nz, feature_list)"
   ],
   "id": "265b44dc61be676e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create dataset with selected features (excluding posx, posy)\n",
    "# X_train_selected = X_train[feature_list]\n",
    "# X_test_selected = X_test[feature_list]\n",
    "\n",
    "X_train_selected = X_train_scaled[feature_list]\n",
    "X_test_selected = X_test_scaled[feature_list]\n",
    "X_validation_selected = X_validation_scaled[feature_list]\n",
    "\n",
    "# Convert labels to binary classification (0 vs all)\n",
    "y_train_binary = np.where(y_train == 0, 0, 1)\n",
    "y_test_binary = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "# Apply ADASYN for class imbalance handling\n",
    "adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=10)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train_binary)\n",
    "# X_train_adasyn, y_train_multi = X_train_selected, y_train\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model on binary data\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = rf_model.predict(X_test_selected)\n",
    "\n",
    "y_validation_pred = rf_model.predict(X_validation_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_binary, y_test_pred, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_binary, y_test_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_binary, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "print(f\"\\nTrain Accuracy: {train_accuracy:.3f}, Train Balanced Accuracy: {train_balanced_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}, Test Balanced Accuracy: {test_balanced_acc:.3f}\")\n",
    "\n",
    "\n",
    "# Function to create and plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.nan_to_num(cm_norm)  # Replace NaN with 0\n",
    "\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.3f', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1], ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_binary, y_test_pred, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "376e50309c20825d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hard_spots_test_index = y_test_pred == 1\n",
    "hard_spots_test = X_test_new_nz[hard_spots_test_index]\n",
    "y_test_hard = y_test[hard_spots_test_index]\n",
    "\n",
    "hard_spots_val_index = y_validation != 0\n",
    "hard_spots_validation = X_val_new_nz[hard_spots_val_index]\n",
    "y_validation_hard = y_validation[hard_spots_val_index]\n",
    "\n",
    "# y_train_pred = rf_model.predict(X_train[feature_list])\n",
    "hard_spots_train_index = y_train != 0\n",
    "hard_spots_train = X_train_nz[hard_spots_train_index]\n",
    "y_train_hard = y_train[hard_spots_train_index]"
   ],
   "id": "fa381afac4490ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import *\n",
    "\n",
    "\n",
    "def grid_max_smooth(df, features_to_smooth, grid_range=1):\n",
    "    \"\"\"\n",
    "    Efficiently smooth each feature using a 3x3 grid around each point.\n",
    "    \"\"\"\n",
    "    df_smoothed = df.copy()\n",
    "\n",
    "    # Create a spatial index - a dictionary mapping (x,y) to row index position O(1) - instead of repeated search\n",
    "    spatial_index = {}\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        spatial_index[(row['posx'], row['posy'])] = i\n",
    "\n",
    "    # Process each feature\n",
    "    for feature in features_to_smooth:\n",
    "        if feature not in df.columns or feature in ['posx', 'posy', 'label']:\n",
    "            continue\n",
    "\n",
    "        feature_values = df[feature].values  # Cache the feature values array\n",
    "        smoothed_values = np.empty_like(feature_values)\n",
    "\n",
    "        # For each position in the original dataframe\n",
    "        for i, (idx, row) in enumerate(df.iterrows()):\n",
    "            x, y = row['posx'], row['posy']\n",
    "            grid_values = []\n",
    "\n",
    "            # Check each cell in the 3x3 grid\n",
    "            for dx in range(-grid_range, grid_range + 1):\n",
    "                for dy in range(-grid_range, grid_range + 1):\n",
    "                    # Use the spatial index for direct lookup\n",
    "                    grid_pos = (x + dx, y + dy)\n",
    "                    if grid_pos in spatial_index:\n",
    "                        pos = spatial_index[grid_pos]\n",
    "                        grid_values.append(feature_values[pos])\n",
    "\n",
    "            # Take the maximum of the values found in the grid\n",
    "            smoothed_values[i] = max(grid_values) if grid_values else feature_values[i]\n",
    "\n",
    "        # Assign all values at once\n",
    "        df_smoothed[feature] = smoothed_values\n",
    "\n",
    "    return df_smoothed\n",
    "\n",
    "\n",
    "# Apply kNN median smoothing to train set\n",
    "hard_spots_train_smoothed = grid_max_smooth(\n",
    "    hard_spots_train,\n",
    "    feature_list,\n",
    ")\n",
    "\n",
    "# Apply kNN median smoothing to test set\n",
    "hard_spots_test_smoothed = grid_max_smooth(\n",
    "    hard_spots_test,\n",
    "    feature_list,\n",
    ")\n",
    "\n",
    "# Apply kNN median smoothing to validation set\n",
    "hard_spots_validation_smoothed = grid_max_smooth(\n",
    "    hard_spots_validation,\n",
    "    feature_list,\n",
    ")\n",
    "\n",
    "# # Visualize the smoothing effect for each feature\n",
    "# for feature in feature_list:\n",
    "#     plot_smoothing_effect(\n",
    "#         hard_spots_test,\n",
    "#         hard_spots_test_smoothed,\n",
    "#         hard_spots_train,\n",
    "#         hard_spots_train_smoothed,\n",
    "#         feature\n",
    "#     )\n"
   ],
   "id": "992da227c6b3ecac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Full Classifier",
   "id": "b52a137be2c5df8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_confusion_matrix\n",
    "\n",
    "# test_index = y_test_pred == 1\n",
    "# X_test_new_nz = X_test_new[test_index]\n",
    "# y_test_nz = y_test[test_index]\n",
    "#\n",
    "# train_index = y_train != 0\n",
    "# X_train_nz = X_train[train_index]\n",
    "# y_train_nz = y_train[train_index]\n",
    "#\n",
    "# X_train_selected = X_train_nz[feature_list]\n",
    "# X_test_selected = X_test_new_nz[feature_list]  #X_test  --- X_test_new\n",
    "\n",
    "X_train_selected = hard_spots_train_smoothed[feature_list]\n",
    "X_test_selected = hard_spots_test_smoothed[feature_list]\n",
    "y_train_nz = y_train_hard\n",
    "y_test_nz = y_test_hard\n",
    "\n",
    "# Apply ADASYN for adaptive oversampling\n",
    "# adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5)\n",
    "# X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "X_train_adasyn, y_train_adasyn = X_train_selected, y_train_nz\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_nz = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_nz, y_test_pred_nz, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_nz, y_test_pred_nz, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4478eee696ff2186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_confusion_matrix\n",
    "\n",
    "test_index = y_test_pred == 1\n",
    "X_test_new_nz = X_test_scaled[test_index]\n",
    "y_test_nz = y_test[test_index]\n",
    "\n",
    "train_index = y_train != 0\n",
    "X_train_nz = X_train_scaled[train_index]\n",
    "y_train_nz = y_train[train_index]\n",
    "\n",
    "X_train_selected = X_train_nz[feature_list]\n",
    "X_test_selected = X_test_new_nz[feature_list]  #X_test  --- X_test_new\n",
    "\n",
    "# X_train_selected = hard_spots_train_smoothed[feature_list]\n",
    "# X_test_selected = hard_spots_test_smoothed[feature_list]\n",
    "# y_train_nz = y_train_hard\n",
    "# y_test_nz = y_test_hard\n",
    "\n",
    "# Apply ADASYN for adaptive oversampling\n",
    "# adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5)\n",
    "# X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "X_train_adasyn, y_train_adasyn = X_train_selected, y_train_nz\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_nz = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_nz, y_test_pred_nz, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_nz, y_test_pred_nz, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "46230253030baee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "class TwoStageClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, binary_model=None, multiclass_model=None, features=None, train_smoothed=None):\n",
    "        self.binary_model = binary_model\n",
    "        self.multiclass_model = multiclass_model\n",
    "        self.features = features\n",
    "        self.train_smoothed = train_smoothed\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        y_binary = (y != 0).astype(int)\n",
    "        mask = y != 0\n",
    "\n",
    "        adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=10)\n",
    "        X_adasyn, y_binary_adasyn = adasyn.fit_resample(X[self.features], y_binary)\n",
    "\n",
    "        self.binary_model_ = clone(self.binary_model)\n",
    "        self.binary_model_.fit(X_adasyn, y_binary_adasyn)\n",
    "\n",
    "        self.multiclass_model_ = clone(self.multiclass_model)\n",
    "        X_hard_smoothed = self.train_smoothed[self.features]\n",
    "        y_multiclass = y[mask] - 1\n",
    "\n",
    "        self.multiclass_model_.fit(X_hard_smoothed, y_multiclass)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        binary_preds = self.binary_model_.predict(X[self.features])\n",
    "        idx = binary_preds == 1\n",
    "\n",
    "        X_hard_smoothed = grid_max_smooth(\n",
    "            X[idx],\n",
    "            self.features\n",
    "        )\n",
    "\n",
    "        final_preds = np.zeros(X.shape[0], dtype=int)\n",
    "        if np.any(idx):\n",
    "            final_preds[idx] = self.multiclass_model_.predict(X_hard_smoothed[self.features]) + 1\n",
    "\n",
    "        return final_preds\n",
    "\n"
   ],
   "id": "f80a2164cfd98c2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of model hyperparameters definitions\n",
    "models = [\n",
    "    {\n",
    "        'model': SVC(kernel='rbf'),\n",
    "        'hyperparameters': {\n",
    "            'C': [0.1, 1],\n",
    "            'gamma': [0.01, 0.1, 1],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': RandomForestClassifier(n_jobs=-1, bootstrap=True, criterion='entropy', max_features=0.5, n_estimators=200),\n",
    "        'hyperparameters': {\n",
    "            'max_depth': [None, 10],\n",
    "            'min_samples_split': [15, 20, 25],\n",
    "            'min_samples_leaf': [2, 5, 8]\n",
    "        }\n",
    "    }\n",
    "#   {\n",
    "#         'model': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "#         'hyperparameters': {\n",
    "#             'n_estimators': [100, 200],\n",
    "#             'max_depth': [4, 6],\n",
    "#             'gamma': [i / 10.0 for i in range(0, 4)]\n",
    "#         }\n",
    "#     }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Function to generate all combinations of binary and multiclass classifiers\n",
    "def generate_combinations(models):\n",
    "    combinations = []\n",
    "\n",
    "    # Generate combinations for binary and multiclass model pairs\n",
    "    for binary_model, multiclass_model in product(models, repeat=2):\n",
    "        binary_model_params = binary_model['hyperparameters']\n",
    "        multiclass_model_params = multiclass_model['hyperparameters']\n",
    "\n",
    "        # Construct a dict for each combination\n",
    "        param_dict = {\n",
    "            'binary_model': [binary_model['model']],\n",
    "            **{f'binary_model__{k}': v for k, v in binary_model_params.items()},\n",
    "            'multiclass_model': [multiclass_model['model']],\n",
    "            **{f'multiclass_model__{k}': v for k, v in multiclass_model_params.items()},\n",
    "            'features': list(results_df['features'])\n",
    "        }\n",
    "\n",
    "        combinations.append(param_dict)\n",
    "\n",
    "    return combinations\n",
    "\n",
    "\n",
    "# Generate the combinations\n",
    "param_grid = generate_combinations(models)\n",
    "param_grid"
   ],
   "id": "42c234532cc5952d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "clf = TwoStageClassifier(train_smoothed=hard_spots_train_smoothed)\n",
    "\n",
    "X_train_final = X_train_scaled.copy()\n",
    "X_train_final[\"posy\"] = X_train[\"posy\"]\n",
    "X_train_final[\"posx\"] = X_train[\"posx\"]\n",
    "\n",
    "X_test_final = X_test_scaled.copy()\n",
    "X_test_final[\"posx\"] = X_test[\"posx\"]\n",
    "X_test_final[\"posy\"] = X_test[\"posy\"]\n",
    "\n",
    "X_val_final = X_validation_scaled.copy()\n",
    "X_val_final[\"posx\"] = X_validation[\"posx\"]\n",
    "X_val_final[\"posy\"] = X_validation[\"posy\"]\n",
    "\n",
    "X_train_val = pd.concat([X_train_final, X_val_final], axis=0)\n",
    "y_train_val = pd.concat([y_train, y_validation], axis=0)\n",
    "\n",
    "test_fold = [-1] * len(X_train_final) + [0] * len(X_val_final)\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    error_score='raise',\n",
    "    cv=ps,\n",
    "    n_jobs=-1,\n",
    "    refit=False,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ],
   "id": "76078d6b044f8074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred, label=\"Set\"):\n",
    "    print(f\"\\n=== {label} Metrics ===\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score (macro):  {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create base estimators\n",
    "binary_model = clone(best_params['binary_model'])\n",
    "multiclass_model = clone(best_params['multiclass_model'])\n",
    "best_features = best_params['features'] + [\"posx\", \"posy\"]\n",
    "\n",
    "# Apply parameters to the two models\n",
    "for param, value in best_params.items():\n",
    "    if param.startswith('binary_model__'):\n",
    "        param_name = param.replace('binary_model__', '')\n",
    "        setattr(binary_model, param_name, value)\n",
    "    if param.startswith('multiclass_model__'):\n",
    "        param_name = param.replace('multiclass_model__', '')\n",
    "        setattr(multiclass_model, param_name, value)\n",
    "\n",
    "# setattr(multiclass_model, \"C\", 18)\n",
    "# # setattr(multiclass_model, \"kernel\", \"poly\")\n",
    "# setattr(multiclass_model, \"gamma\", 0.1)\n",
    "#\n",
    "\n",
    "# Create classifier with the configured models\n",
    "best_clf = TwoStageClassifier(\n",
    "    binary_model=binary_model,\n",
    "    multiclass_model=multiclass_model,\n",
    "    features= best_params['features'],\n",
    "    train_smoothed=hard_spots_train_smoothed\n",
    ")\n",
    "\n",
    "# Now fit and evaluate as before\n",
    "best_clf.fit(X_train_final[best_features], y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = best_clf.predict(X_test_final[best_features])\n",
    "y_pred_train = best_clf.predict(X_train_final[best_features])\n",
    "y_pred_val = best_clf.predict(X_val_final[best_features])\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(28, 7))\n",
    "plot_confusion_matrix(y_train, y_pred_train, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_validation, y_pred_val, 'Validation Data Confusion Matrix', ax2)\n",
    "plot_confusion_matrix(y_test, y_pred_test, 'Test Data Confusion Matrix', ax3)\n",
    "\n",
    "# Print performance metrics\n",
    "print_metrics(y_test, y_pred_test, label=\"Test\")\n"
   ],
   "id": "faa92e2528ea183d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NEW PROPOSED PIPELINE",
   "id": "9ac939007cfecf27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing the dataset",
   "id": "ddb2177f3483d8ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:48:27.652671Z",
     "start_time": "2025-04-30T10:48:27.648181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "8a51e8f662ba34c7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:48:30.345390Z",
     "start_time": "2025-04-30T10:48:30.286327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = smoothed_train.copy()\n",
    "df2 = smoothed_validation.copy()\n",
    "df3 = smoothed_test.copy()\n",
    "\n",
    "# Assigning group\n",
    "df1['group'] = 1\n",
    "df2['group'] = 2\n",
    "df3['group'] = 3\n",
    "\n",
    "# Train contains the union of df1 and df2 coming from two measure with different parameters of the same object\n",
    "train_df = pd.concat([df1, df2], axis = 0, ignore_index=True)\n",
    "X_train = train_df.drop(['label', 'group', 'posx', 'posy'], axis=1)\n",
    "y_train = train_df['label']\n",
    "groups_train = train_df['group']\n",
    "# Test will be done on a new object\n",
    "X_test = df3.drop(['label', 'group', 'posx', 'posy'], axis=1)\n",
    "y_test = df3['label']\n",
    "groups_test = df3['group']"
   ],
   "id": "9bd6ba266ab93e18",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model development",
   "id": "92bd7e519e8b6baf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:48:37.819523Z",
     "start_time": "2025-04-30T10:48:32.578850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import Modeldev as md\n",
    "print(\"Performing nested cross-validation...\")\n",
    "classifier_names = ['rf', 'svc', 'xgb', 'logistic', 'gb']\n",
    "cv_results = md.nested_cross_validation(\n",
    "    X_train, y_train, groups_train,\n",
    "    n_outer_splits=8, n_trials=30,\n",
    "    classifier_names=classifier_names,\n",
    "    metric='f1_macro'\n",
    ")\n",
    "\n",
    "md.plot_evaluation_metrics(cv_results)\n",
    "\n",
    "print(\"Selecting best classifiers for each stage...\")\n",
    "best_classifiers = md.get_best_classifiers(cv_results, metric='f1_macro')\n",
    "\n",
    "print(\"Best classifiers:\")\n",
    "for stage, info in best_classifiers.items():\n",
    "    print(f\"  {stage}: {info['classifier_name']} (score: {info['score']:.4f})\")\n",
    "\n",
    "final_model, test_metrics = train_final_model(\n",
    "    X_train, y_train, X_test, y_test, best_classifiers\n",
    ")\n",
    "\n",
    "print(\"Plotting confusion matrix...\")\n",
    "md.plot_confusion_matrices(test_metrics)\n",
    "\n",
    "# Step 7: Plot ROC curves\n",
    "print(\"Plotting ROC curves...\")\n",
    "md.plot_roc_curves(test_metrics)\n"
   ],
   "id": "d1d23667032bb166",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-30 12:48:36,943] A new study created in memory with name: no-name-a74b1c76-d9f6-42a7-b4ce-2612378f62c6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing nested cross-validation...\n",
      "\n",
      "Training rf in outer CV fold...\n",
      "Optimizing Stage 1 (binary) classifier...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'f1_macro'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPerforming nested cross-validation...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m classifier_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msvc\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mxgb\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogistic\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgb\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 4\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mmd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnested_cross_validation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_outer_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclassifier_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclassifier_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mf1_macro\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m md\u001B[38;5;241m.\u001B[39mplot_evaluation_metrics(cv_results)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelecting best classifiers for each stage...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Artificial touch\\Modeldev.py:589\u001B[0m, in \u001B[0;36mnested_cross_validation\u001B[1;34m(X, y, groups, n_outer_splits, n_trials, classifier_names, metric)\u001B[0m\n\u001B[0;32m    587\u001B[0m \u001B[38;5;66;03m# Stage 1: Binary classifier optimization with inner CV\u001B[39;00m\n\u001B[0;32m    588\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizing Stage 1 (binary) classifier...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 589\u001B[0m stage1_best_params, stage1_best_score \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_pipeline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_outer_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_binary_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups_outer_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclf_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;66;03m# Create Stage 1 pipeline with optimized parameters\u001B[39;00m\n\u001B[0;32m    595\u001B[0m stage1_pipeline \u001B[38;5;241m=\u001B[39m create_optimized_pipeline(\n\u001B[0;32m    596\u001B[0m     clf_name, stage1_best_params, X_outer_train\n\u001B[0;32m    597\u001B[0m )\n",
      "File \u001B[1;32mD:\\Artificial touch\\Modeldev.py:411\u001B[0m, in \u001B[0;36moptimize_pipeline\u001B[1;34m(X, y, groups, classifier_name, stage, n_trials, metric)\u001B[0m\n\u001B[0;32m    406\u001B[0m objective_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m trial: objective(\n\u001B[0;32m    407\u001B[0m     trial, X, y, groups, classifier_name, stage, metric\n\u001B[0;32m    408\u001B[0m )\n\u001B[0;32m    410\u001B[0m \u001B[38;5;66;03m# Run optimization\u001B[39;00m\n\u001B[1;32m--> 411\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(objective_func, n_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m)\u001B[49m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    413\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m study\u001B[38;5;241m.\u001B[39mbest_params, study\u001B[38;5;241m.\u001B[39mbest_value\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'f1_macro'"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
