{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TABLE CREATION",
   "id": "70191282af507847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from CreateTable import create_df\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# data_test = create_df(\"DamasconeC/together/*_CPXE_*.csv\", symm_v = True, angle=-1, offset=(52, 51))  # , symmetric = True\n",
    "# data_train = create_df(\"DamasconeA/data2/*_CPXE_*.csv\", offset=(49, 51), angle=1)\n",
    "# data_train = create_df(\"DamasconeB/together/*_CPXE_*.csv\")\n",
    "data_train = pd.read_pickle(\"DamasconeA2.pkl\")\n",
    "\n",
    "data_validation = pd.read_pickle(\"DamasconeA.pkl\")\n",
    "# data_train2 = data_train2.drop(columns=[\"Row\"])\n",
    "\n",
    "data_test = pd.read_pickle(\"DamasconeB.pkl\")\n",
    "# data_test = pd.read_pickle(\"C_norm_ss.pkl\")\n",
    "\n",
    "# to be handled properly TODO\n",
    "data_train = data_train.dropna()\n",
    "data_test = data_test.dropna()\n",
    "data_validation = data_validation.dropna()\n"
   ],
   "id": "8521e62c79249487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data_train['stiffness_to_relaxation'] = data_train['Stiffness'] / data_train['force_relaxation']\n",
    "data_train['oscillation_to_max_force'] = data_train['force_oscillation'] / data_train['force_max']\n",
    "\n",
    "data_test['stiffness_to_relaxation'] = data_test['Stiffness'] / data_test['force_relaxation']\n",
    "data_test['oscillation_to_max_force'] = data_test['force_oscillation'] / data_test['force_max']\n",
    "\n",
    "data_validation['stiffness_to_relaxation'] = data_validation['Stiffness'] / data_validation['force_relaxation']\n",
    "data_validation['oscillation_to_max_force'] = data_validation['force_oscillation'] / data_validation['force_max']\n"
   ],
   "id": "38dc38f85ffa1939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_test.to_pickle('B_norm_ss.pkl')",
   "id": "6bf2716810f7492a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helper import feature_list2\n",
    "\n",
    "# Create dataset with selected features (no posx, posy)\n",
    "# feature_list_time = [ 'Stiffness', 'Upstroke', 'P_ss']\n",
    "# feature_list_hysteresis = ['peak_position','loading_energy']\n",
    "# feature_list = feature_list_time + feature_list_hysteresis\n",
    "# feature_list = feature_list2\n",
    "#\n",
    "# to_remove = ['segment2_slope', 'segment2_force_std',\n",
    "#              'segment2_skew', 'segment3_skew', 'Downstroke', 'poly3_coef0',\n",
    "#              'poly5_coef0', 'poly5_coef1', 'poly5_coef2', 'poly5_coef3', 'poly5_coef4', 'Entropy', \"Tau\", 'P_ss',\n",
    "#              'offset', 'force_relaxation', 'force_ratio_75_25', 'hysteresis_area'\n",
    "#              ]\n",
    "#\n",
    "# feature_list = [x for x in feature_list2 + ['stiffness_to_relaxation', 'oscillation_to_max_force'] if x not in to_remove]\n",
    "# feature_list = ['loading_unloading_area_ratio', 'peak_width', 'stiffness_to_relaxation', 'Stiffness']\n",
    "feature_list = [\"Stiffness\", \"Upstroke\", \"Downstroke\", \"P_ss\", \"peak_position\", \"loading_energy\"]"
   ],
   "id": "60ea06290a3d387b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PLOTS",
   "id": "fcdfadeb7e07286e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def plot_aligned_samples(df, label_column, force_column, pos_column, threshold=0.1, max_samples_per_label=5):\n",
    "    unique_labels = (0, 1, 2, 3, 4, 5)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "    used_labels = set()  # Track labels for legend\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get all samples for this label\n",
    "        label_df = df[df[label_column] == label]\n",
    "\n",
    "        # Downsample if too many samples\n",
    "        if len(label_df) > max_samples_per_label:\n",
    "            label_df = resample(label_df, n_samples=max_samples_per_label, random_state=42)\n",
    "\n",
    "        for _, sample in label_df.iterrows():\n",
    "            # Extract force and position\n",
    "            force = np.array(sample[force_column])\n",
    "            position = np.array(sample[pos_column])\n",
    "\n",
    "            # Find alignment point\n",
    "            force_above_threshold = force > threshold\n",
    "            if np.any(force_above_threshold):\n",
    "                start_idx = np.where(force_above_threshold)[0][0]\n",
    "\n",
    "                # Label only the first occurrence of each label\n",
    "                label_text = f'Label {label}' if label not in used_labels else None\n",
    "                used_labels.add(label)\n",
    "\n",
    "                # Plot aligned data\n",
    "                axes.plot(position - position[start_idx], force, label=label_text, alpha=0.7)\n",
    "\n",
    "    # Set plot properties\n",
    "    axes.set_xlabel('Position')\n",
    "    axes.set_xlim(left=-0.001)\n",
    "    axes.set_ylabel('Force')\n",
    "    axes.set_title('Force over Time (Aligned)')\n",
    "    axes.legend()\n",
    "    axes.grid()\n",
    "\n",
    "    plt.suptitle('Aligned Sample Plot')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "plot_aligned_samples(data_train, label_column='label', force_column='Fi', pos_column='Pi', threshold=0.05,\n",
    "                     max_samples_per_label=1)\n"
   ],
   "id": "b43f1becae2eabd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_aligned_samples(df, label_column, force_column, pos_column, time_column, n=1, threshold=0.1):\n",
    "    unique_labels = df[label_column].unique()  # Get unique labels\n",
    "    unique_labels = (0, 1, 2, 3, 4, 5)\n",
    "\n",
    "    for i in range(n):  # Repeat n times\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "        for label in unique_labels:\n",
    "            # Randomly select one sample per label\n",
    "            sample = df[df[label_column] == label].sample(1, random_state=np.random.randint(0, 10000))\n",
    "\n",
    "            # Extract force, position, and time\n",
    "            force = np.array(sample[force_column].tolist()[0])\n",
    "            position = np.array(sample[pos_column].tolist()[0])\n",
    "            time = np.array(sample[time_column].tolist()[0])\n",
    "\n",
    "            # Find the first index where force rises above the threshold\n",
    "            start_idx = np.where(force > threshold)[0][0]\n",
    "\n",
    "            # Align the time axis so that this point is at t = 0\n",
    "            time_aligned = time - time[start_idx]\n",
    "\n",
    "            # Plot force vs. time (left subplot)\n",
    "            axes[0].plot(time_aligned, force, label=f'Label {label}')\n",
    "            axes[0].set_xlabel('Time (Aligned)')\n",
    "            axes[0].set_ylabel('Force')\n",
    "            axes[0].set_title('Force over Time (Aligned)')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid()\n",
    "\n",
    "            # Plot position vs. time (right subplot)\n",
    "            axes[1].plot(time_aligned, position, label=f'Label {label}')\n",
    "            axes[1].set_xlabel('Time (Aligned)')\n",
    "            axes[1].set_ylabel('Position')\n",
    "            axes[1].set_title('Position over Time (Aligned)')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid()\n",
    "\n",
    "        plt.suptitle(f'Aligned Sample Plot {i + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "plot_aligned_samples(data_train, label_column='label', force_column='Fi', pos_column='Pi', time_column='Timei', n=2,\n",
    "                     threshold=0.05)"
   ],
   "id": "5daa61e410e7acdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPATIAL SMOOTHING",
   "id": "17ad70bb5a386364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.interpolate import NearestNDInterpolator\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "smoothing_config = {\n",
    "    'Entropy': 'gaussian',\n",
    "}  # Dictionary 'feature-name' : type of smoothing (set if you want to test other method of smoothing instead of median)\n",
    "\n",
    "\n",
    "def apply_smoothing(grid_z, method='median'):\n",
    "    if method == 'median':\n",
    "        return median_filter(grid_z, size=3, mode='reflect')\n",
    "    elif method == 'gaussian':\n",
    "        return gaussian_filter(grid_z, sigma=2)\n",
    "    elif method == 'diffusion':\n",
    "        # Simple anisotropic diffusion\n",
    "        def diffusion_step(img, kappa=50):\n",
    "            # Compute image gradients\n",
    "            dy, dx = np.gradient(img)\n",
    "\n",
    "            # Compute diffusion coefficients\n",
    "            diff_coef_x = 1 / (1 + (dx / kappa) ** 2)\n",
    "            diff_coef_y = 1 / (1 + (dy / kappa) ** 2)\n",
    "\n",
    "            # Compute diffusion\n",
    "            diff_x = np.zeros_like(img)\n",
    "            diff_y = np.zeros_like(img)\n",
    "\n",
    "            diff_x[1:-1, 1:-1] = diff_coef_x[1:-1, 1:-1] * (img[1:-1, 2:] - img[1:-1, 1:-1])\n",
    "            diff_y[1:-1, 1:-1] = diff_coef_y[1:-1, 1:-1] * (img[2:, 1:-1] - img[1:-1, 1:-1])\n",
    "\n",
    "            return img + 0.25 * (diff_x + diff_y)\n",
    "\n",
    "        # Apply multiple diffusion steps\n",
    "        iterations = 20\n",
    "        img = grid_z.copy()\n",
    "        for i in range(iterations):\n",
    "            img = diffusion_step(img)\n",
    "        return img\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Smoothing method not implemented: {method}\")\n",
    "\n",
    "\n",
    "def get_grid_bounds(df):\n",
    "    x_min, x_max = int(df[\"posx\"].min()), int(df[\"posx\"].max())\n",
    "    y_min, y_max = int(df[\"posy\"].min()), int(df[\"posy\"].max())\n",
    "    grid_shape = (y_max - y_min + 1, x_max - x_min + 1)\n",
    "    return x_min, y_min, grid_shape\n",
    "\n",
    "\n",
    "# Smoothing function for a single dataframe\n",
    "def smooth_subset(subset_df, x_min, y_min, grid_shape):\n",
    "    smoothed_subset = pd.DataFrame(index=subset_df.index)\n",
    "\n",
    "    for feature in feature_list:\n",
    "        # Initialize grid with NaNs\n",
    "        grid_z = np.full(grid_shape, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Map each data point to the grid\n",
    "        for _, row in subset_df.iterrows():\n",
    "            x_idx = int(row[\"posx\"]) - x_min\n",
    "            y_idx = int(row[\"posy\"]) - y_min\n",
    "            grid_z[y_idx, x_idx] = row[feature]\n",
    "\n",
    "        # Interpolate missing values\n",
    "        yy, xx = np.indices(grid_z.shape)\n",
    "        valid_mask = ~np.isnan(grid_z)\n",
    "\n",
    "        if np.any(~valid_mask):\n",
    "            interpolator = NearestNDInterpolator(\n",
    "                np.column_stack((yy[valid_mask], xx[valid_mask])),\n",
    "                grid_z[valid_mask]\n",
    "            )\n",
    "            grid_z = interpolator(yy, xx)\n",
    "\n",
    "        # Apply feature-specific smoothing\n",
    "        methods = smoothing_config.get(feature,\n",
    "                                       'median')  # Get the designed methods, if None select defaul 'median' method\n",
    "        if isinstance(methods, list):\n",
    "            for method in methods:\n",
    "                grid_z = apply_smoothing(grid_z, method=method)\n",
    "        else:\n",
    "            grid_z = apply_smoothing(grid_z, method=methods)\n",
    "\n",
    "        # Map smoothed grid back to DataFrame\n",
    "        smoothed_subset[feature] = [\n",
    "            grid_z[int(row[\"posy\"]) - y_min, int(row[\"posx\"]) - x_min]\n",
    "            for _, row in subset_df.iterrows()\n",
    "        ]\n",
    "\n",
    "    # Add back metadata columns\n",
    "    smoothed_subset[['label', 'posx', 'posy']] = subset_df[['label', 'posx', 'posy']]\n",
    "    return smoothed_subset\n",
    "\n",
    "\n",
    "if smoothing_config is None:\n",
    "    smoothing_config = {feature: 'median' for feature in feature_list}\n",
    "\n",
    "# Compute grid bounds and smooth each subset\n",
    "test_x_min, test_y_min, test_grid_shape = get_grid_bounds(data_test)\n",
    "train_x_min, train_y_min, train_grid_shape = get_grid_bounds(data_train)\n",
    "\n",
    "# Smooth each subset SEPARATELY\n",
    "smoothed_test = smooth_subset(data_test, test_x_min, test_y_min, test_grid_shape)\n",
    "smoothed_train = smooth_subset(data_train, train_x_min, train_y_min, train_grid_shape)\n",
    "smoothed_validation = smooth_subset(data_validation, train_x_min, train_y_min, train_grid_shape)\n",
    "\n",
    "smoothed_df = pd.concat([smoothed_test, smoothed_train],\n",
    "                        ignore_index=True)  # For visualization in the next sections only"
   ],
   "id": "99d148d49061a836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DB SPLITTING",
   "id": "4b301ca0f0f71e01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "# Display class distribution\n",
    "X = smoothed_df[feature_list + [\"posx\", \"posy\"]]\n",
    "y = smoothed_df['label']\n",
    "\n",
    "# train_df = pd.concat([train_df1, train_df2], ignore_index=True)\n",
    "# smoothed_train = pd.concat([smoothed_train1, smoothed_train2], ignore_index=True)\n",
    "\n",
    "# Training distribution:\n",
    "class_distribution = Counter(smoothed_train['label'])\n",
    "print(\"Class distribution in the dataset:\")\n",
    "for label, count in sorted(class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y) * 100:.2f}%)\")\n",
    "\n",
    "# Test distribution:\n",
    "class_distribution = Counter(smoothed_test['label'])\n",
    "print(\"Class distribution in the dataset:\")\n",
    "for label, count in sorted(class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y) * 100:.2f}%)\")\n",
    "\n",
    "# Prepare data for classification\n",
    "X_train = smoothed_train[feature_list + [\"posx\", \"posy\"]]\n",
    "y_train = smoothed_train['label']\n",
    "\n",
    "X_validation = smoothed_validation[feature_list + [\"posx\", \"posy\"]]\n",
    "y_validation = smoothed_validation['label']\n",
    "\n",
    "X_test = smoothed_test[feature_list + [\"posx\", \"posy\"]]\n",
    "y_test = smoothed_test['label']\n",
    "\n",
    "# Preprocess data  -  No need a scaler in Random FOREST!!!!, if other model, apply after the splitting\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X_train_scaled = X_train\n",
    "# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_list + [\"posx\", \"posy\"], index=X.index)\n",
    "# X_test_scaled = X_test\n",
    "# X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_list + [\"posx\", \"posy\"], index=X.index)\n",
    "\n",
    "\n",
    "# Create the figure and axes: 2 rows (train/test), then 3 histograms\n",
    "fig, axs = plt.subplots(2, 4, figsize=(22, 14), gridspec_kw={'width_ratios': [3, 1, 1, 1]})\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create consistent color map using turbo\n",
    "unique_labels = sorted(data_train['label'].unique())  # or union of train + test if needed\n",
    "palette_colors = sns.color_palette(\"turbo\", n_colors=len(unique_labels))\n",
    "label_color_dict = {label: color for label, color in zip(unique_labels, palette_colors)}\n",
    "\n",
    "# Plot train\n",
    "sns.scatterplot(\n",
    "    data=data_train,\n",
    "    x='posx',\n",
    "    y='posy',\n",
    "    hue='label',\n",
    "    palette=label_color_dict,  # Use fixed mapping\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_title(\"Train Set Distribution (posx vs posy)\")\n",
    "axs[0, 0].set_xlabel(\"Position X (posx)\")\n",
    "axs[0, 0].set_ylabel(\"Position Y (posy)\")\n",
    "axs[0, 0].legend(title='Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot test with same label-color mapping\n",
    "sns.scatterplot(\n",
    "    data=data_test,\n",
    "    x='posx',\n",
    "    y='posy',\n",
    "    hue='label',\n",
    "    palette=label_color_dict,  # Same dictionary ensures color consistency\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_title(\"Test Set Distribution (posx vs posy)\")\n",
    "axs[1, 0].set_xlabel(\"Position X (posx)\")\n",
    "axs[1, 0].set_ylabel(\"Position Y (posy)\")\n",
    "axs[1, 0].legend(title='Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# --- Histograms / Class Distribution Plots ---\n",
    "plot_class_distribution(smoothed_df['label'], axs[0, 1], \"Class Dist. (Entire)\")\n",
    "plot_class_distribution(y_train, axs[0, 2], \"Class Dist. (Train)\")\n",
    "plot_class_distribution(y_test, axs[0, 3], \"Class Dist. (Test)\")\n",
    "\n",
    "# Hide the unused bottom row histograms\n",
    "for ax in axs[1, 1:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # Drop posx and posy columns from the training and testing sets after plotting\n",
    "# X_train = X_train.drop(columns=['posx', 'posy'])\n",
    "# X_test = X_test.drop(columns=['posx', 'posy'])"
   ],
   "id": "934212b578e97c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Binary Classifier",
   "id": "25ce08865461ab20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_train1 = StandardScaler()\n",
    "scaler_train2 = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "X_train_selected = X_train[feature_list]\n",
    "X_validation_selected = X_validation[feature_list]\n",
    "X_test_selected = X_test[feature_list]\n",
    "\n",
    "# X_train_selected_1 = X_train_selected[X_train[\"posy\"] <= 140]\n",
    "# X_train_selected_2 = X_train_selected[X_train[\"posy\"] > 140]\n",
    "\n",
    "X_train_scaled = scaler_train1.fit_transform(X_train_selected)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_list, index=X_train_selected.index)\n",
    "\n",
    "X_validation_scaled = scaler_train1.fit_transform(X_validation_selected)\n",
    "X_validation_scaled = pd.DataFrame(X_validation_scaled, columns=feature_list, index=X_validation_selected.index)\n",
    "\n",
    "# X_train_scaled2 = scaler_train2.fit_transform(X_train_selected_2)\n",
    "\n",
    "# X_train_scaled1 = pd.DataFrame(X_train_scaled1, columns=feature_list, index=X_train_selected_1.index)\n",
    "# X_train_scaled2 = pd.DataFrame(X_train_scaled2, columns=feature_list, index=X_train_selected_2.index)\n",
    "# X_train_scaled = pd.concat([X_train_scaled1, X_train_scaled2]).sort_index()\n",
    "\n",
    "X_test_scaled = scaler_test.fit_transform(X_test_selected)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_list, index=X_test_selected.index)"
   ],
   "id": "9b855847b244c914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create dataset with selected features (excluding posx, posy)\n",
    "# X_train_selected = X_train[feature_list]\n",
    "# X_test_selected = X_test[feature_list]\n",
    "\n",
    "X_train_selected = X_train_scaled\n",
    "X_test_selected = X_test_scaled\n",
    "\n",
    "# Convert labels to binary classification (0 vs all)\n",
    "y_train_binary = np.where(y_train == 0, 0, 1)\n",
    "y_test_binary = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "# Apply ADASYN for class imbalance handling\n",
    "adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=10)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train_binary)\n",
    "# X_train_adasyn, y_train_multi = X_train_selected, y_train\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model on binary data\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_binary, y_test_pred, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_binary, y_test_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_binary, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "print(f\"\\nTrain Accuracy: {train_accuracy:.3f}, Train Balanced Accuracy: {train_balanced_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}, Test Balanced Accuracy: {test_balanced_acc:.3f}\")\n",
    "\n",
    "\n",
    "# Function to create and plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.nan_to_num(cm_norm)  # Replace NaN with 0\n",
    "\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.3f', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1], ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_binary, y_test_pred, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "376e50309c20825d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from binary_classification_adjustment import *\n",
    "\n",
    "X_test_new = adjust_test_features(X_train, y_train, X_test, y_test_pred)[feature_list]"
   ],
   "id": "91742e538b067a7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_features\n",
    "\n",
    "X_test_new = X_test\n",
    "Xa = X_train_selected.copy()\n",
    "Xa[\"label\"] = y_train_binary\n",
    "Xa[\"posx\"] = X_train[\"posx\"]\n",
    "Xa[\"posy\"] = X_train[\"posy\"]\n",
    "\n",
    "Xb = X_test_selected.copy()\n",
    "Xb[\"label\"] = y_test_binary\n",
    "Xb[\"posx\"] = X_test[\"posx\"]\n",
    "Xb[\"posy\"] = X_test[\"posy\"]\n",
    "\n",
    "X_new_test = Xb.copy()\n",
    "X_new_test[\"label\"] = y_test\n",
    "\n",
    "X_new_train = Xa.copy()\n",
    "X_new_train[\"label\"] = y_train\n",
    "\n",
    "plot_features(Xa, Xb, feature_list)"
   ],
   "id": "af8a2f259fe5fa8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract posx and posy from X_test (ensure they are NumPy arrays)\n",
    "posx = np.array(X_test['posx'])\n",
    "posy = np.array(X_test['posy'])\n",
    "\n",
    "# Ensure y_test and y_test_pred are NumPy arrays\n",
    "y_test_pred = np.array(y_test_pred)\n",
    "\n",
    "# Identify misclassified points\n",
    "misclassified = y_test_binary != y_test_pred\n",
    "\n",
    "# Create figure with two vertically stacked subplots\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "\n",
    "# Use 'plasma' colormap for better contrast\n",
    "cmap = 'turbo'\n",
    "\n",
    "# Initialize lists to store legend handles\n",
    "scatter_plots = []\n",
    "\n",
    "# First subplot: Color by true labels\n",
    "sc = axes[0].scatter(posx[~misclassified], posy[~misclassified],\n",
    "                     c=y_test_binary[~misclassified], cmap=cmap, marker='o', label='Correctly Classified')\n",
    "\n",
    "sc_misclassified = axes[0].scatter(posx[misclassified], posy[misclassified],\n",
    "                                   c=y_test_binary[misclassified], cmap=cmap, marker='x',\n",
    "                                   linewidth=1, label='Misclassified')\n",
    "\n",
    "axes[0].set_title('True Labels with Misclassified Points')\n",
    "axes[0].set_ylabel('posy')\n",
    "\n",
    "# Second subplot: Color by predicted labels\n",
    "sc_pred = axes[1].scatter(posx[~misclassified], posy[~misclassified],\n",
    "                          c=y_test_pred[~misclassified], cmap=cmap, marker='o', label='Correctly Classified')\n",
    "\n",
    "sc_pred_misclassified = axes[1].scatter(posx[misclassified], posy[misclassified],\n",
    "                                        c=y_test_pred[misclassified], cmap=cmap, marker='x',\n",
    "                                        linewidth=1, label='Misclassified')\n",
    "\n",
    "axes[1].set_title('Predicted Labels with Misclassified Points')\n",
    "axes[1].set_xlabel('posx')\n",
    "axes[1].set_ylabel('posy')\n",
    "\n",
    "# Collect legend handles and labels\n",
    "handles = [sc, sc_misclassified]\n",
    "labels = ['Correctly Classified', 'Misclassified']\n",
    "\n",
    "# Create one global legend outside the plot\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2, fontsize=12)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c35ffc4e5615f171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hard_spots_test_index = y_test_pred == 1\n",
    "hard_spots_test = X_test[hard_spots_test_index]\n",
    "y_test_hard = y_test[hard_spots_test_index]\n",
    "\n",
    "# y_train_pred = rf_model.predict(X_train[feature_list])\n",
    "hard_spots_train_index = y_train != 0\n",
    "hard_spots_train = X_train[hard_spots_train_index]\n",
    "y_train_hard = y_train[hard_spots_train_index]\n",
    "\n",
    "print(X_train.shape)\n",
    "hard_spots_train.shape"
   ],
   "id": "fa381afac4490ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "def reverse_weighted_smooth(df, features_to_smooth, bandwidth=4.0, center_emphasis=3.0):\n",
    "    # Create a copy of the dataframe to store smoothed values\n",
    "    df_smoothed = df.copy()\n",
    "\n",
    "    # Extract spatial coordinates\n",
    "    coords = df[['posx', 'posy']].values\n",
    "\n",
    "    # Use DBSCAN to identify clusters\n",
    "    clustering = DBSCAN(eps=2.0, min_samples=10).fit(coords)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    # Find cluster centers\n",
    "    centers = []\n",
    "    center_indices = []\n",
    "\n",
    "    for label in np.unique(labels):\n",
    "        if label == -1:  # Skip noise points\n",
    "            continue\n",
    "\n",
    "        # Get points in this cluster\n",
    "        cluster_mask = labels == label\n",
    "        cluster_points = coords[cluster_mask]\n",
    "\n",
    "        # Calculate centroid\n",
    "        centroid = np.mean(cluster_points, axis=0)\n",
    "        centers.append(centroid)\n",
    "\n",
    "        # Find the point closest to the centroid\n",
    "        distances_to_centroid = np.sum((cluster_points - centroid) ** 2, axis=1)\n",
    "        closest_point_idx = np.where(cluster_mask)[0][np.argmin(distances_to_centroid)]\n",
    "        center_indices.append(closest_point_idx)\n",
    "\n",
    "    # Apply smoothing to each feature\n",
    "    for feature in features_to_smooth:\n",
    "        if feature in df.columns and feature not in ['posx', 'posy', 'label']:\n",
    "            # Get feature values as array\n",
    "            feature_values = df[feature].values.copy()\n",
    "            original_values = feature_values.copy()\n",
    "\n",
    "            # For each point, calculate weighted average based on distance\n",
    "            for i in range(len(coords)):\n",
    "                # Calculate distances to all other points\n",
    "                dists = np.sqrt(np.sum((coords - coords[i]) ** 2, axis=1))\n",
    "\n",
    "                # Create weights with Gaussian kernel\n",
    "                kernel_weights = np.exp(-0.5 * (dists / bandwidth) ** 2)\n",
    "\n",
    "                # Determine if this point is a center\n",
    "                is_center = i in center_indices\n",
    "\n",
    "                if is_center:\n",
    "                    # For center points, preserve their original value or even emphasize it\n",
    "                    central_value = original_values[i]\n",
    "                    # Blend with weighted average, but give more weight to the original center value\n",
    "                    avg_value = np.sum(kernel_weights * original_values) / np.sum(kernel_weights)\n",
    "                    feature_values[i] = (central_value * center_emphasis + avg_value) / (center_emphasis + 1)\n",
    "                else:\n",
    "                    # Regular smoothing for non-center points\n",
    "                    feature_values[i] = np.sum(kernel_weights * original_values) / np.sum(kernel_weights)\n",
    "\n",
    "            # Update the smoothed dataframe\n",
    "            df_smoothed[feature] = feature_values\n",
    "\n",
    "    return df_smoothed, centers, center_indices, labels\n",
    "\n",
    "\n",
    "def visualize_clusters_and_centers(df, center_indices, labels, ax, title):\n",
    "    # Create a colormap for clusters\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    # Plot points colored by cluster\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        if label == -1:\n",
    "            # Black for noise points\n",
    "            cluster_color = 'black'\n",
    "        else:\n",
    "            cluster_color = colors[i]\n",
    "\n",
    "        mask = labels == label\n",
    "        ax.scatter(df.loc[mask, 'posx'], df.loc[mask, 'posy'],\n",
    "                   c=[cluster_color], edgecolor='k', s=50,\n",
    "                   alpha=0.6)\n",
    "\n",
    "    # Plot centers with X markers\n",
    "    center_points = df.iloc[center_indices][['posx', 'posy']].values\n",
    "    ax.scatter(center_points[:, 0], center_points[:, 1],\n",
    "               c='red', marker='X', s=200, edgecolor='k')\n",
    "\n",
    "    ax.set_title(f'{title} with Cluster Centers')\n",
    "    ax.set_xlabel('posx')\n",
    "    ax.set_ylabel('posy')\n",
    "\n",
    "\n",
    "features_to_smooth = [f for f in feature_list if f not in ['posx', 'posy']]\n",
    "hard_spots_test_smoothed, centers, center_indices, labels = reverse_weighted_smooth(\n",
    "    hard_spots_test, features_to_smooth, bandwidth=3.0, center_emphasis=0.00001)\n",
    "\n",
    "hard_spots_train_smoothed, centers2, center_indices2, labels2 = reverse_weighted_smooth(\n",
    "    hard_spots_train, features_to_smooth, bandwidth=3.0, center_emphasis=0.00001)\n",
    "\n",
    "# Visualize the clusters and centers7\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "visualize_clusters_and_centers(hard_spots_test, center_indices, labels, axes[1], \"test\")\n",
    "visualize_clusters_and_centers(hard_spots_train, center_indices2, labels2, axes[0], \"train\")\n",
    "\n",
    "\n",
    "# Plot the smoothing effect for comparison\n",
    "def plot_smoothing_effect(test_original, test_smooth, train_original, train_smoothed, feature):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "    # Plot original values\n",
    "    sc1 = axes[1][0].scatter(test_original['posx'], test_original['posy'],\n",
    "                             c=test_original[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[1][0].set_title(f\"Test: Original {feature}\")\n",
    "    axes[1][0].set_xlabel(\"posx\")\n",
    "    axes[1][0].set_ylabel(\"posy\")\n",
    "\n",
    "    sc1 = axes[0][0].scatter(train_original['posx'], train_original['posy'],\n",
    "                             c=train_original[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[0][0].set_title(f\"Train: Original {feature}\")\n",
    "    axes[0][0].set_xlabel(\"posx\")\n",
    "    axes[0][0].set_ylabel(\"posy\")\n",
    "\n",
    "    # Plot smoothed values\n",
    "    sc2 = axes[1][1].scatter(test_smooth['posx'], test_smooth['posy'],\n",
    "                             c=test_smooth[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[1][1].set_title(f\"Test: Smoothed {feature}\")\n",
    "    axes[1][1].set_xlabel(\"posx\")\n",
    "    axes[1][1].set_ylabel(\"posy\")\n",
    "\n",
    "    sc2 = axes[0][1].scatter(train_smoothed['posx'], train_smoothed['posy'],\n",
    "                             c=train_smoothed[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[0][1].set_title(f\"Train: Smoothed {feature}\")\n",
    "    axes[0][1].set_xlabel(\"posx\")\n",
    "    axes[0][1].set_ylabel(\"posy\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for feature in features_to_smooth:\n",
    "    plot_smoothing_effect(hard_spots_test, hard_spots_test_smoothed, hard_spots_train, hard_spots_train_smoothed,\n",
    "                          feature)"
   ],
   "id": "2f21ffde98ecf84c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Full Classifier",
   "id": "b52a137be2c5df8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_confusion_matrix\n",
    "\n",
    "test_index = y_test_pred == 1\n",
    "X_test_new_nz = X_test_new[test_index]\n",
    "y_test_nz = y_test[test_index]\n",
    "\n",
    "train_index = y_train != 0\n",
    "X_train_nz = X_train[train_index]\n",
    "y_train_nz = y_train[train_index]\n",
    "\n",
    "X_train_selected = X_train_nz[feature_list]\n",
    "X_test_selected = X_test_new_nz[feature_list]  #X_test  --- X_test_new\n",
    "\n",
    "# X_train_selected = hard_spots_train_smoothed\n",
    "# X_test_selected = hard_spots_test_smoothed\n",
    "# y_train = y_train_hard\n",
    "# y_test = y_test_hard\n",
    "\n",
    "# Apply ADASYN for adaptive oversampling\n",
    "# adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5)\n",
    "# X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "X_train_adasyn, y_train_adasyn = X_train_selected, y_train_nz\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_nz = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_nz, y_test_pred_nz, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_nz, y_test_pred_nz, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4478eee696ff2186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# For binary classification, shap_values[1] is for class 1\n",
    "shap.summary_plot(shap_values[1], X_test)"
   ],
   "id": "3a1014c50899b761",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract posx and posy from X_test (ensure they are NumPy arrays)\n",
    "posx = np.array(X_test['posx'])\n",
    "posy = np.array(X_test['posy'])\n",
    "\n",
    "# Ensure y_test and y_test_pred are NumPy arrays\n",
    "y_test = np.array(y_test)\n",
    "y_test_pred = np.array(y_test_pred)\n",
    "\n",
    "# Identify misclassified points\n",
    "misclassified = y_test != y_test_pred\n",
    "\n",
    "# Create figure with two vertically stacked subplots\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "\n",
    "# Use 'plasma' colormap for better contrast\n",
    "cmap = 'turbo'\n",
    "\n",
    "# Initialize lists to store legend handles\n",
    "scatter_plots = []\n",
    "\n",
    "# First subplot: Color by true labels\n",
    "sc = axes[0].scatter(posx[~misclassified], posy[~misclassified],\n",
    "                     c=y_test[~misclassified], cmap=cmap, marker='o', label='Correctly Classified')\n",
    "\n",
    "sc_misclassified = axes[0].scatter(posx[misclassified], posy[misclassified],\n",
    "                                   c=y_test[misclassified], cmap=cmap, marker='x',\n",
    "                                   linewidth=1, label='Misclassified')\n",
    "\n",
    "axes[0].set_title('True Labels with Misclassified Points')\n",
    "axes[0].set_ylabel('posy')\n",
    "\n",
    "# Second subplot: Color by predicted labels\n",
    "sc_pred = axes[1].scatter(posx[~misclassified], posy[~misclassified],\n",
    "                          c=y_test_pred[~misclassified], cmap=cmap, marker='o', label='Correctly Classified')\n",
    "\n",
    "sc_pred_misclassified = axes[1].scatter(posx[misclassified], posy[misclassified],\n",
    "                                        c=y_test_pred[misclassified], cmap=cmap, marker='x',\n",
    "                                        linewidth=1, label='Misclassified')\n",
    "\n",
    "axes[1].set_title('Predicted Labels with Misclassified Points')\n",
    "axes[1].set_xlabel('posx')\n",
    "axes[1].set_ylabel('posy')\n",
    "\n",
    "# Collect legend handles and labels\n",
    "handles = [sc, sc_misclassified]\n",
    "labels = ['Correctly Classified', 'Misclassified']\n",
    "\n",
    "# Create one global legend outside the plot\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2, fontsize=12)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "e8ca12e18e353c6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# --- Random Forest Feature Importances ---\n",
    "\n",
    "# Assuming rf_model is your trained model and top_features is your list of features\n",
    "\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances and sort them\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_list,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "# --- Mutual Information Scores ---\n",
    "\n",
    "X = data_train[feature_list]\n",
    "y = data_train['label']\n",
    "\n",
    "# Compute mutual information scores for each feature\n",
    "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "\n",
    "X2 = smoothed_train[feature_list]\n",
    "y2 = smoothed_train['label']\n",
    "\n",
    "# Compute mutual information scores for each feature (smoothed)\n",
    "mi_scores2 = mutual_info_classif(X2, y2, random_state=42)\n",
    "\n",
    "# Create a DataFrame for mutual information scores and sort them\n",
    "\n",
    "\n",
    "# --- Mutual Information on Test Set ---\n",
    "X_test_mi = smoothed_test[feature_list]\n",
    "y_test_mi = smoothed_test['label']\n",
    "mi_scores_test = mutual_info_classif(X_test_mi, y_test_mi, random_state=42)\n",
    "\n",
    "X_validation_mi = smoothed_validation[feature_list]\n",
    "y_validation_mi = smoothed_validation['label']\n",
    "mi_scores_validation = mutual_info_classif(X_validation_mi, y_validation_mi, random_state=42)\n",
    "\n",
    "# Combine all MI scores\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': feature_list,\n",
    "    'original': mi_scores,\n",
    "    'smoothed': mi_scores2,\n",
    "    'test': mi_scores_test,\n",
    "    'validation': mi_scores_validation\n",
    "}).sort_values('original', ascending=True)\n",
    "\n",
    "# Select only label 3, 4, 5 from train and test\n",
    "selected_labels = [3, 4, 5]\n",
    "train_mask = y_train.isin(selected_labels)\n",
    "test_mask = y_test.isin(selected_labels)\n",
    "\n",
    "X_train_filtered = X_train_selected[train_mask]\n",
    "X_test_filtered = X_test_selected[test_mask]\n",
    "\n",
    "# --- Compute Wasserstein distance for each feature ---\n",
    "distance_data = {\n",
    "    'feature': [],\n",
    "    'wasserstein_distance': []\n",
    "}\n",
    "\n",
    "for feat in feature_list:\n",
    "    train_feat = X_train_filtered[feat]\n",
    "    test_feat = X_test_filtered[feat]\n",
    "    distance = wasserstein_distance(train_feat, test_feat)\n",
    "    distance_data['feature'].append(feat)\n",
    "    distance_data['wasserstein_distance'].append(distance)\n",
    "\n",
    "# distance_df = pd.DataFrame(distance_data).sort_values('wasserstein_distance', ascending=True)\n",
    "distance_df = pd.DataFrame(distance_data)\n",
    "\n",
    "# 3 subplots: Importance | Mutual Info | Distance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 9), sharey=True)\n",
    "\n",
    "# 1. Random Forest Feature Importances\n",
    "sns.barplot(x='importance', y='feature', data=importance_df, palette='viridis', ax=axes[0], hue=\"feature\", legend=False)\n",
    "axes[0].set_title('Random Forest Feature Importances', fontsize=16)\n",
    "axes[0].set_xlabel('Importance', fontsize=12)\n",
    "axes[0].set_ylabel('Features', fontsize=12)\n",
    "\n",
    "# 2. Mutual Information: Original, Smoothed, Test\n",
    "bar_width = 0.45\n",
    "y_positions = np.arange(len(mi_df))\n",
    "ax = axes[1]\n",
    "\n",
    "ax.barh(y_positions, mi_df['original'], height=bar_width, color='red', alpha=0.6, label='Original')\n",
    "ax.barh(y_positions, mi_df['smoothed'], height=bar_width, color='blue', alpha=0.6, label='Smoothed')\n",
    "ax.barh(y_positions + bar_width, mi_df['test'], height=bar_width, color='green', alpha=0.6, label='Test')\n",
    "\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(mi_df['feature'])\n",
    "ax.set_title('Mutual Information Scores', fontsize=16)\n",
    "ax.set_xlabel('Mutual Info Score', fontsize=12)\n",
    "ax.set_ylabel('')\n",
    "ax.legend()\n",
    "\n",
    "# 3. Train/Test Distribution Distance\n",
    "sns.barplot(x='wasserstein_distance', y='feature', data=distance_df, palette='mako', ax=axes[2], hue='feature',\n",
    "            legend=False)\n",
    "axes[2].set_title('Train vs Test Wasserstein Distance', fontsize=16)\n",
    "axes[2].set_xlabel('Distance', fontsize=12)\n",
    "axes[2].set_ylabel('')\n",
    "axes[2].set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combine everything into a single DataFrame for easy filtering\n",
    "combined_df = mi_df.merge(distance_df, on='feature')\n",
    "\n",
    "# Filter by the given conditions\n",
    "selected_features = combined_df[\n",
    "    # (combined_df['smoothed'] > 0.4) &\n",
    "    # (combined_df['test'] > 0.4) &\n",
    "    (combined_df['wasserstein_distance'] < 0.12)\n",
    "]\n",
    "\n",
    "# Output the feature names\n",
    "print(\"âœ… Features with MI (smoothed train & test > 0.4) and Wasserstein < 0.05:\")\n",
    "print(selected_features['feature'].tolist())"
   ],
   "id": "10032d9769443475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_features\n",
    "\n",
    "hard_spots_test[\"label\"] = y_test_hard\n",
    "hard_spots_train[\"label\"] = y_train_hard\n",
    "\n",
    "hard_spots_test_smoothed = hard_spots_test_smoothed.copy()\n",
    "hard_spots_test_smoothed[\"label\"] = y_test_hard\n",
    "\n",
    "hard_spots_train_smoothed = hard_spots_train_smoothed.copy()\n",
    "hard_spots_train_smoothed[\"label\"] = y_train_hard\n",
    "\n",
    "# Call function with datasets\n",
    "plot_features(hard_spots_train_smoothed, hard_spots_test_smoothed, feature_list)\n",
    "print(\"\\n\\n\")\n",
    "X_train_nz = X_train_nz.copy()\n",
    "X_train_nz[\"label\"] = y_train_nz\n",
    "\n",
    "X_test_new_nz = X_test_new_nz.copy()\n",
    "X_test_new_nz[\"label\"] = y_test_nz\n",
    "\n",
    "plot_features(X_train_nz, X_test_new_nz, feature_list)\n"
   ],
   "id": "e27c96d5c2aee587",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define models in a list of tuples (name, model instance)\n",
    "models = [\n",
    "    ('SVM', SVC(kernel='rbf', C=0.5, gamma='scale', probability=True, random_state=42)),  # n_jobs not supported\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2, n_jobs=-1)),\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
    "    # no n_jobs\n",
    "    ('Naive Bayes', GaussianNB()),  # no n_jobs\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),  # no n_jobs\n",
    "    ('MLP Neural Net', MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)),  # no n_jobs\n",
    "]\n",
    "\n",
    "\n",
    "def fit_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "\n",
    "    for i, (name, model) in enumerate(models):\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        train_bal_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "        test_bal_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        print(f\"{name} Training Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"{name} Training Balanced Accuracy: {train_bal_acc:.4f}\")\n",
    "        print(f\"{name} Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"{name} Test Balanced Accuracy: {test_bal_acc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Train Accuracy': train_acc,\n",
    "            'Train Balanced Accuracy': train_bal_acc,\n",
    "            'Test Accuracy': test_acc,\n",
    "            'Test Balanced Accuracy': test_bal_acc\n",
    "        })\n",
    "\n",
    "        # Plot for this model\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plot_confusion_matrix(y_train, y_train_pred, f'{name} - Train', axes[0])\n",
    "        plot_confusion_matrix(y_test, y_test_pred, f'{name} - Test', axes[1])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example call\n",
    "results = fit_and_evaluate_models(models, X_train_adasyn, y_train_adasyn, X_test_selected, y_test)\n",
    "\n",
    "\n",
    "# Plot comparison bar chart\n",
    "def plot_model_comparison(results):\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df_melted = df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df_melted, x='Model', y='Score', hue='Metric')\n",
    "    plt.title('Model Comparison')\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_model_comparison(results)\n"
   ],
   "id": "4bbde64cffef6a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standard scikit-learn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "models = [\n",
    "    # Ensemble methods that handle imbalance well\n",
    "    ('XGBoost', XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=2,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # LightGBM - fast and handles complex relationships well\n",
    "    ('LightGBM', LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        feature_fraction=0.8,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # Voting classifier combining your best models\n",
    "    ('Voting Classifier', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "            ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)),\n",
    "            ('svm', SVC(probability=True, kernel='rbf'))\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )),\n",
    "\n",
    "    # CatBoost - handles categorical features well and often outperforms\n",
    "    ('CatBoost', CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )),\n",
    "\n",
    "    # Extremely Randomized Trees - reduces variance compared to RF\n",
    "    ('Extra Trees', ExtraTreesClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # Deep MLP with dropout for better generalization\n",
    "    ('Deep Neural Net', MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50, 25),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.0001,\n",
    "        batch_size='auto',\n",
    "        learning_rate='adaptive',\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.2,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "results = fit_and_evaluate_models(models, X_train_adasyn, y_train_adasyn, X_test_selected, y_test)\n",
    "plot_model_comparison(results)\n"
   ],
   "id": "50633d79ba508478",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class_weights = {0: 1, 1: 1, 2: 1, 3: 3, 4: 3, 5: 3}\n",
    "\n",
    "# Apply to any model that supports class_weight\n",
    "weighted_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=class_weights,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pca_svm = Pipeline([\n",
    "    ('pca', PCA(n_components=15, random_state=42)),\n",
    "    ('svm', SVC(kernel='rbf', probability=True))\n",
    "])\n",
    "\n",
    "tsne_rf = Pipeline([\n",
    "    ('tsne', TSNE(n_components=3, random_state=42, perplexity=30, n_jobs=-1)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, n_jobs=-1))\n",
    "])\n",
    "\n",
    "models = [('RF', weighted_rf), ('PCA', pca_svm), ('TSNE', tsne_rf)]\n",
    "\n",
    "results = fit_and_evaluate_models(models, X_train_adasyn, y_train_adasyn, X_test_selected, y_test)\n",
    "plot_model_comparison(results)"
   ],
   "id": "d73751ac364c8d5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Apply t-SNE on the test set (2D)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=10, n_jobs=-1)\n",
    "X_test_tsne = tsne.fit_transform(X_test_selected)\n",
    "\n",
    "# Plot t-SNE results with actual test labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_test_tsne[:, 0], X_test_tsne[:, 1], c=y_test, cmap='tab10', alpha=0.7)\n",
    "plt.colorbar(scatter, ticks=range(len(set(y_test))))\n",
    "plt.title(\"t-SNE projection (2D) of Test Set\")\n",
    "plt.xlabel(\"TSNE-1\")\n",
    "plt.ylabel(\"TSNE-2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Optionally: print as DataFrame\n",
    "df_tsne = pd.DataFrame({\n",
    "    'TSNE-1': X_test_tsne[:, 0],\n",
    "    'TSNE-2': X_test_tsne[:, 1],\n",
    "    'Label': y_test\n",
    "})\n",
    "print(df_tsne.head())\n"
   ],
   "id": "90f1379adb53ee85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Features Extraction",
   "id": "3c644c2cbbab7841"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "dfs = {idx: pd.DataFrame({'time': row['t'], 'Fz_s': row['Fz_s']})\n",
    "       for idx, row in data_train.iterrows()}\n",
    "\n",
    "long_df = pd.concat([df.assign(id=idx) for idx, df in dfs.items()], ignore_index=True)\n",
    "\n",
    "# Step 1: Extract features from the time series data.\n",
    "extracted_features = extract_features(long_df, column_id=\"id\", column_sort=\"time\", column_value=\"Fz_s\")\n",
    "\n",
    "# Step 2: Impute any missing values that might have resulted from the extraction process.\n",
    "imputed_features = impute(extracted_features)\n",
    "\n",
    "# Step 3: Select features that significantly correlate with the labels.\n",
    "relevant_features = select_features(imputed_features, data_train[\"label\"], fdr_level=0.0000001)  # Stricter selection"
   ],
   "id": "6a9899dbfcee2d28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# Create a dictionary of DataFrames for each row in smoothed_train\n",
    "\n",
    "# data_train_features = data_train[(data_train['posy'] > 99) & (data_train['posy'] < 101)]\n",
    "data_train_features = data_train\n",
    "\n",
    "dfs = {\n",
    "    idx: pd.DataFrame({\n",
    "        'time': row['Timei'][::4],\n",
    "        'Fz_s': row['Fi'][::4],\n",
    "        'Pz_s': row['Pi'][::4],\n",
    "    }) for idx, row in data_train_features.iterrows()\n",
    "}\n",
    "\n",
    "# Convert to long format by stacking Fz_s and Pz_s under a new 'kind' column\n",
    "long_df = pd.concat(\n",
    "    [df.assign(id=idx).melt(id_vars=['time', 'id'], var_name='kind', value_name='value') for idx, df in dfs.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "long_df"
   ],
   "id": "cd294e3648ce21be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tsfresh.feature_extraction import MinimalFCParameters, EfficientFCParameters\n",
    "\n",
    "# Extract features from both Fz_s and Pz_s\n",
    "extracted_features = extract_features(\n",
    "    long_df,\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time\",\n",
    "    column_kind=\"kind\",\n",
    "    column_value=\"value\",\n",
    "    n_jobs=8,\n",
    "    default_fc_parameters=EfficientFCParameters()\n",
    ")\n",
    "\n",
    "# Impute missing values\n",
    "imputed_features = impute(extracted_features)\n",
    "\n",
    "# Select relevant features\n",
    "relevant_features = select_features(imputed_features, data_train_features[\"label\"], fdr_level=0.05)\n"
   ],
   "id": "9875bb31401ddf03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Compute mutual information scores\n",
    "mi_scores = mutual_info_classif(imputed_features, data_train[\"label\"])\n",
    "\n",
    "# Create DataFrame with feature importance\n",
    "feature_importance = pd.DataFrame({\"feature\": imputed_features.columns, \"importance\": mi_scores})\n",
    "\n",
    "# Sort features by importance (highest first)\n",
    "top_20_features = feature_importance.sort_values(by=\"importance\", ascending=False).head(20)\n",
    "\n",
    "# Extract the corresponding feature columns from the dataset\n",
    "top_20_feature_names = top_20_features[\"feature\"].tolist()\n",
    "top_20_selected = imputed_features[top_20_feature_names]\n",
    "\n",
    "print(f\"Top 20 Most Informative Features:\\n{top_20_selected.columns}\")\n"
   ],
   "id": "b64850d351429e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tsfresh.feature_extraction import extract_features, EfficientFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "dfs = {\n",
    "    idx: pd.DataFrame({\n",
    "        'time': row['Timei'][::4],\n",
    "        'Fz_s': row['Fi'][::4],\n",
    "        'Pz_s': row['Pi'][::4],\n",
    "    }) for idx, row in data_test.iterrows()\n",
    "}\n",
    "\n",
    "# Convert to long format by stacking Fz_s and Pz_s under a new 'kind' column\n",
    "long_df_test = pd.concat(\n",
    "    [df.assign(id=idx).melt(id_vars=['time', 'id'], var_name='kind', value_name='value') for idx, df in dfs.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# 1. Extract all features on test set (same settings as train)\n",
    "test_features = extract_features(\n",
    "    long_df_test,\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time\",\n",
    "    column_kind=\"kind\",\n",
    "    column_value=\"value\",\n",
    "    n_jobs=8,\n",
    "    default_fc_parameters=EfficientFCParameters()\n",
    ")\n",
    "\n",
    "# 2. Impute missing values\n",
    "test_features_imputed = impute(test_features)\n",
    "\n",
    "# 3. Select only your topâ€‘20 feature columns\n",
    "test_top20 = test_features_imputed[top_20_feature_names].copy()\n",
    "\n",
    "# 4. (Optional) verify\n",
    "print(f\"Computed topâ€‘20 features on test set:\\n{test_top20.columns.tolist()}\")\n",
    "print(f\"Shape: {test_top20.shape}\")\n"
   ],
   "id": "2a875d81638a54d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Train/Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     top_20_selected,\n",
    "#     data_train_features[\"label\"],\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "X_train, X_test, y_train, y_test = top_20_selected, test_top20, data_train_features[\"label\"], data_test[\"label\"]\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 1) Overall accuracy in percent\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "# 2) Raw confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=sorted(set(y_test)))\n",
    "\n",
    "# 3) Normalize to percentages\n",
    "#    - overall: divide by total samples\n",
    "cm_pct_total = cm / cm.sum() * 100\n",
    "#    - or perâ€class (rows): divide each row by its sum\n",
    "cm_pct_rows = cm.astype(float)\n",
    "row_sums = cm_pct_rows.sum(axis=1)[:, np.newaxis]\n",
    "cm_pct_rows = (cm_pct_rows / row_sums) * 100\n",
    "\n",
    "# 4) Plot normalized (rowâ€wise) confusion matrix as percentages\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm_pct_rows,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=sorted(set(y_test)),\n",
    "    yticklabels=sorted(set(y_test))\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion Matrix (per class %)\")\n",
    "plt.show()\n"
   ],
   "id": "8ae9b133ee3dd50d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
