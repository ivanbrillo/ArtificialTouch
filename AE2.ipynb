{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from DataParser import get_df_list\n",
    "\n",
    "# df's containing only the signals captured when the machine is touching\n",
    "df_list = get_df_list()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def alpha_trimmed_mean_filter(data: list, win_size: int, alpha: int) -> list:\n",
    "    n = len(data)\n",
    "    result = [0] * (n - win_size)\n",
    "\n",
    "    assert win_size > alpha > 0 and alpha % 4 == 0 and win_size % 2 == 0\n",
    "\n",
    "    for i in range(win_size // 2, n - win_size // 2):\n",
    "        window = data[i - win_size // 2:i + win_size // 2]\n",
    "        window.sort()\n",
    "        result[i - win_size // 2] = sum(window[alpha // 4:win_size - (alpha // 4) * 3]) / (win_size - alpha)\n",
    "\n",
    "    return  [result[0]] * (win_size // 2) + result + [result[-1]] * (win_size // 2)\n",
    "\n",
    "\n",
    "for df in df_list:\n",
    "    df[\"posz\"] = alpha_trimmed_mean_filter(list(df[\"posz\"]), win_size=20, alpha=8)\n",
    "    df[\"Fz\"] = alpha_trimmed_mean_filter(list(df[\"Fz\"]), win_size=20, alpha=8)\n",
    "\n"
   ],
   "id": "af13b326292fe7a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def interpolate(list_dataframes: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    interpolated_list = []\n",
    "\n",
    "    for element in list_dataframes:\n",
    "        # Create cubic interpolation function\n",
    "        interp_func1 = interp1d(element['t'], element['posz'], kind='cubic')\n",
    "        interp_func2 = interp1d(element['t'], element['Fz'], kind='cubic')\n",
    "\n",
    "        # Define new time points with a constant interval\n",
    "        t_new = np.arange(element['t'].min(), element['t'].max(), 0.003)  # Adjust step size as needed\n",
    "        posz_new = interp_func1(t_new)\n",
    "        fz_new = interp_func2(t_new)\n",
    "\n",
    "        # Create new DataFrame with interpolated values\n",
    "        df_interp = pd.DataFrame({'t': t_new, 'posz': posz_new, 'Fz': fz_new})\n",
    "        interpolated_list.append(df_interp)\n",
    "    return interpolated_list\n",
    "\n",
    "interpolated = interpolate(df_list)"
   ],
   "id": "d2ecf1052d3c8aec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pad_time_series(dataframes: list[pd.DataFrame]) -> list[pd.DataFrame]:\n",
    "    # max_length = max(len(df) for df in dataframes)  # Find longest series\n",
    "    lengths = sorted(set(len(df) for df in dataframes), reverse=True)  # Get unique lengths in descending order\n",
    "    second_max_length = lengths[1] if len(lengths) > 1 else None  # Get second maximum if available\n",
    "\n",
    "    padded_dfs = []\n",
    "    for df in dataframes:\n",
    "        pad_size = second_max_length - len(df)\n",
    "        \n",
    "        if pad_size > 0:  # If this series is shorter, pad it\n",
    "            last_row = df.iloc[-1]  # Get last row values\n",
    "            pad_df = pd.DataFrame([last_row] * pad_size)  # Repeat last row\n",
    "            df = pd.concat([df, pad_df], ignore_index=True)  # Append padding\n",
    "            \n",
    "            padded_dfs.append(df)\n",
    "\n",
    "    return padded_dfs\n",
    "\n",
    "\n",
    "padded_df = pad_time_series(interpolated)\n",
    "print(len(padded_df[0]))"
   ],
   "id": "63a68bd8112bfd6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "\n",
    "def get_auto():\n",
    "    # Encoder\n",
    "    encoder = tf.keras.Sequential([\n",
    "        layers.Input(shape=(702, 2)),\n",
    "        layers.Conv1D(filters=32, kernel_size=32, activation='relu', padding='same'),\n",
    "        layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "        layers.Conv1D(filters=64, kernel_size=16, activation='relu', padding='same'),\n",
    "        layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "        layers.Conv1D(filters=128, kernel_size=8, activation='relu', padding='same'),\n",
    "        layers.MaxPool1D(pool_size=2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(16, activation='linear'),\n",
    "    ])\n",
    "\n",
    "    # Decoder\n",
    "    decoder = tf.keras.Sequential([\n",
    "        layers.Input(shape=(16,)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(87 * 128, activation='relu'),\n",
    "        layers.Reshape((87, 128)),\n",
    "\n",
    "        layers.UpSampling1D(2),  # 320\n",
    "        layers.Conv1DTranspose(filters=128, kernel_size=8, activation='relu', padding='same'),\n",
    "\n",
    "        layers.UpSampling1D(2),  # 640\n",
    "        layers.Conv1DTranspose(filters=64, kernel_size=16, activation='relu', padding='same'),\n",
    "        layers.ZeroPadding1D(padding=(0, 3)),  # Pad to reach 1286 from 1280\n",
    "\n",
    "        layers.UpSampling1D(2),  # 1280\n",
    "        layers.Conv1DTranspose(filters=32, kernel_size=32, activation='relu', padding='same'),\n",
    "        layers.Conv1DTranspose(filters=2, kernel_size=32, activation='linear', padding='same'),\n",
    "    ])\n",
    "\n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "class AE(Model):\n",
    "    def __init__(self, encoder: tf.keras.Sequential, decoder: tf.keras.Sequential):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def set_trainable(self, trainable):\n",
    "        self.trainable = trainable\n",
    "        self.encoder.trainable = trainable\n",
    "        self.decoder.trainable = trainable\n",
    "\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = AE(*get_auto())\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Display model summary\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()\n",
    "\n"
   ],
   "id": "6cb060d2fec76145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def create_input_signals(df_list: list[pd.DataFrame]) -> np.ndarray:\n",
    "    input_signals = []\n",
    "\n",
    "    for df in df_list:\n",
    "        signal = np.column_stack((df['posz'], df['Fz']))\n",
    "        \n",
    "        if signal.shape != (702, 2):\n",
    "            print(signal.shape) \n",
    "\n",
    "        # Append this signal to the list of input signals\n",
    "        input_signals.append(signal)\n",
    "\n",
    "    # Convert list to numpy array with shape (n_samples, 502, 2)\n",
    "    return np.array(input_signals)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_signals(df_list):\n",
    "    # Extract all signals first\n",
    "    all_signals = create_input_signals(df_list)\n",
    "    \n",
    "    # Reshape to 2D for scaling (samples*timesteps, features)\n",
    "    original_shape = all_signals.shape\n",
    "    reshaped = all_signals.reshape(-1, original_shape[-1])\n",
    "    \n",
    "    # Fit scaler and transform\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(reshaped)\n",
    "    \n",
    "    # Reshape back to original shape\n",
    "    normalized_signals = scaled.reshape(original_shape)\n",
    "    \n",
    "    return normalized_signals, scaler, all_signals  # Return scaler to inverse transform later\n",
    "\n",
    "# Use this instead of direct create_input_signals call\n",
    "X_train, scaler, all_signals = preprocess_signals(padded_df)\n",
    "\n",
    "# X_train = create_input_signals(padded_df)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "# TEST SCALER INVERSE\n",
    "SIGNAL = 1\n",
    "\n",
    "original = all_signals[SIGNAL]\n",
    "sample_input = X_train[SIGNAL] \n",
    "\n",
    "reconstructed = sample_input.reshape(-1, 2)\n",
    "original_scale = scaler.inverse_transform(reconstructed)\n",
    "decoded = original_scale.reshape(sample_input.shape)\n",
    "decoded = decoded.reshape(702, 2)\n",
    "\n",
    "# Plot the original vs decoded signals for the first sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# original = all_signals[1]\n",
    "# decoded = decoded_output[1]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot the original signal\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Signal\")\n",
    "plt.plot(original[:, 0], label='posz')\n",
    "plt.plot(decoded[:, 0], label='posz')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the decoded signal\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Decoded Signal\")\n",
    "plt.plot(original[:, 1], label='Fz')\n",
    "plt.plot(decoded[:, 1], label='Fz')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Normalized Signal\")\n",
    "plt.plot(sample_input[:, 0], label='posz')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "99060b9ccefa6934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "from plot_learning import PlotLearning\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    " \n",
    "log_dir = \"logs/\"\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=50, restore_best_weights=False, monitor=\"val_loss\",\n",
    "                                                  mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(filepath='weights/normalized2.weights.h5', save_best_only=True, monitor=\"val_loss\",\n",
    "                                      mode='min', save_weights_only=True)\n",
    "# Create TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Fit the model with TensorBoard logging\n",
    "autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=500 ,\n",
    "    shuffle=True,\n",
    " \n",
    "    batch_size=512,\n",
    "    verbose=1,\n",
    "\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback, early_stopping, checkpoint_callback, PlotLearning(autoencoder)]\n",
    ")\n",
    "\n",
    "autoencoder.load_weights('weights/normalized2.weights.h5')"
   ],
   "id": "87df909fe3a4b3fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SIGNAL = 5\n",
    "\n",
    "original = all_signals[SIGNAL]\n",
    "sample_input = X_train[SIGNAL] \n",
    "sample_input = sample_input.reshape(1, 702, 2)\n",
    "reconstructed_scaled = autoencoder.predict(sample_input)\n",
    "reconstructed = reconstructed_scaled.reshape(-1, 2)\n",
    "original_scale = scaler.inverse_transform(reconstructed)\n",
    "decoded = original_scale.reshape(sample_input.shape)\n",
    "decoded = decoded.reshape(702, 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the original signal\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"PosZ\")\n",
    "plt.plot(original[:, 0], label='posz original')\n",
    "plt.plot(decoded[:, 0], label='posz decoded')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the decoded signal\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Fz\")\n",
    "plt.plot(original[:, 1], label='Fz original')\n",
    "plt.plot(decoded[:, 1], label='Fz decoded')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "8f40be00efcb9c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Number of signals to display\n",
    "NUM_SIGNALS = 20\n",
    "\n",
    "# Get random indices\n",
    "random_indices = random.sample(range(len(all_signals)), NUM_SIGNALS)\n",
    "\n",
    "# Create a figure with appropriate size\n",
    "plt.figure(figsize=(20, 40))\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # Get original signal\n",
    "    original = all_signals[idx]\n",
    "    \n",
    "    # Prepare input for autoencoder\n",
    "    sample_input = X_train[idx]\n",
    "    sample_input = sample_input.reshape(1, 702, 2)\n",
    "    \n",
    "    # Get reconstruction\n",
    "    reconstructed_scaled = autoencoder.predict(sample_input, verbose = 0)\n",
    "    reconstructed = reconstructed_scaled.reshape(-1, 2)\n",
    "    original_scale = scaler.inverse_transform(reconstructed)\n",
    "    decoded = original_scale.reshape(702, 2)\n",
    "    \n",
    "    # Plot PosZ\n",
    "    plt.subplot(NUM_SIGNALS, 2, 2*i+1)\n",
    "    plt.title(f\"PosZ - Signal {idx}\")\n",
    "    plt.plot(original[:, 0], label='original')\n",
    "    plt.plot(decoded[:, 0], label='decoded')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Fz\n",
    "    plt.subplot(NUM_SIGNALS, 2, 2*i+2)\n",
    "    plt.title(f\"Fz - Signal {idx}\")\n",
    "    plt.plot(original[:, 1], label='original')\n",
    "    plt.plot(decoded[:, 1], label='decoded')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "45e33862964d7261",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
