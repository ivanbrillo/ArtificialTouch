{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TABLE CREATION",
   "id": "70191282af507847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from CreateTable import create_df\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# data_test = create_df(\"DamasconeC/together/*_CPXE_*.csv\", symm_v = True, angle=-1, offset=(52, 51))  # , symmetric = True\n",
    "# data_train = create_df(\"DamasconeA/data2/*_CPXE_*.csv\", offset=(49, 51), angle=1)\n",
    "# data_train = create_df(\"DamasconeB/together/*_CPXE_*.csv\")\n",
    "data_train = pd.read_pickle(\"DamasconeA2.pkl\")\n",
    "\n",
    "data_validation = pd.read_pickle(\"DamasconeA.pkl\")\n",
    "# data_train2 = data_train2.drop(columns=[\"Row\"])\n",
    "\n",
    "data_test = pd.read_pickle(\"DamasconeB.pkl\")\n",
    "# data_test = pd.read_pickle(\"C_norm_ss.pkl\")\n",
    "\n",
    "# to be handled properly TODO\n"
   ],
   "id": "8521e62c79249487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data_train['stiffness_to_relaxation'] = data_train['Stiffness'] / data_train['force_relaxation']\n",
    "data_train['oscillation_to_max_force'] = data_train['force_oscillation'] / data_train['force_max']\n",
    "\n",
    "data_test['stiffness_to_relaxation'] = data_test['Stiffness'] / data_test['force_relaxation']\n",
    "data_test['oscillation_to_max_force'] = data_test['force_oscillation'] / data_test['force_max']\n",
    "\n",
    "data_validation['stiffness_to_relaxation'] = data_validation['Stiffness'] / data_validation['force_relaxation']\n",
    "data_validation['oscillation_to_max_force'] = data_validation['force_oscillation'] / data_validation['force_max']\n",
    "\n",
    "data_train = data_train.dropna()\n",
    "data_test = data_test.dropna()\n",
    "data_validation = data_validation.dropna()\n",
    "\n"
   ],
   "id": "38dc38f85ffa1939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helper import feature_list2\n",
    "\n",
    "# Create dataset with selected features (no posx, posy)\n",
    "# feature_list_time = [ 'Stiffness', 'Upstroke', 'P_ss']\n",
    "# feature_list_hysteresis = ['peak_position','loading_energy']\n",
    "# feature_list = feature_list_time + feature_list_hysteresis\n",
    "feature_list = feature_list2\n",
    "#\n",
    "# to_remove = ['segment2_slope', 'segment2_force_std',\n",
    "#              'segment2_skew', 'segment3_skew', 'Downstroke', 'poly3_coef0',\n",
    "#              'poly5_coef0', 'poly5_coef1', 'poly5_coef2', 'poly5_coef3', 'poly5_coef4', 'Entropy', \"Tau\", 'P_ss',\n",
    "#              'offset', 'force_relaxation', 'force_ratio_75_25', 'hysteresis_area'\n",
    "#              ]\n",
    "#\n",
    "\n",
    "to_remove = ['poly3_coef0', 'poly3_coef1', 'poly3_coef2', 'poly3_coef3',\n",
    "             'poly4_coef0', 'poly4_coef1', 'poly4_coef2', 'poly4_coef3', 'poly4_coef4',\n",
    "             'poly5_coef0', 'poly5_coef1', 'poly5_coef2', 'poly5_coef3', 'poly5_coef4',\n",
    "             # Segmentation features\n",
    "             'segment2_slope', 'segment3_slope', 'segment2_force_std', 'segment3_force_std',\n",
    "             'segment2_skew', 'segment3_skew']\n",
    "\n",
    "feature_list_3 = feature_list = [x for x in feature_list2 + ['stiffness_to_relaxation', 'oscillation_to_max_force'] if\n",
    "                x not in to_remove]\n",
    "# feature_list = ['loading_unloading_area_ratio', 'peak_width', 'stiffness_to_relaxation', 'Stiffness']\n",
    "# feature_list = [\"Stiffness\", \"Upstroke\", \"Downstroke\", \"P_ss\"] #, \"P_ss\", \"loading_energy\"]peak_position\n",
    "\n",
    "# feature_list = ['poly4_coef4', 'poly4_coef3', 'poly5_coef0', 'loading_unloading_area_ratio', 'Stiffness', 'quartic_coefficient', 'Upstroke']"
   ],
   "id": "60ea06290a3d387b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PLOTS",
   "id": "fcdfadeb7e07286e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPATIAL SMOOTHING",
   "id": "17ad70bb5a386364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.interpolate import NearestNDInterpolator\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "smoothing_config = {\n",
    "    'Entropy': 'gaussian',\n",
    "}  # Dictionary 'feature-name' : type of smoothing (set if you want to test other method of smoothing instead of median)\n",
    "\n",
    "\n",
    "def apply_smoothing(grid_z, method='median'):\n",
    "    if method == 'median':\n",
    "        return median_filter(grid_z, size=3, mode='reflect')\n",
    "    elif method == 'gaussian':\n",
    "        return gaussian_filter(grid_z, sigma=2)\n",
    "    elif method == 'diffusion':\n",
    "        # Simple anisotropic diffusion\n",
    "        def diffusion_step(img, kappa=50):\n",
    "            # Compute image gradients\n",
    "            dy, dx = np.gradient(img)\n",
    "\n",
    "            # Compute diffusion coefficients\n",
    "            diff_coef_x = 1 / (1 + (dx / kappa) ** 2)\n",
    "            diff_coef_y = 1 / (1 + (dy / kappa) ** 2)\n",
    "\n",
    "            # Compute diffusion\n",
    "            diff_x = np.zeros_like(img)\n",
    "            diff_y = np.zeros_like(img)\n",
    "\n",
    "            diff_x[1:-1, 1:-1] = diff_coef_x[1:-1, 1:-1] * (img[1:-1, 2:] - img[1:-1, 1:-1])\n",
    "            diff_y[1:-1, 1:-1] = diff_coef_y[1:-1, 1:-1] * (img[2:, 1:-1] - img[1:-1, 1:-1])\n",
    "\n",
    "            return img + 0.25 * (diff_x + diff_y)\n",
    "\n",
    "        # Apply multiple diffusion steps\n",
    "        iterations = 20\n",
    "        img = grid_z.copy()\n",
    "        for i in range(iterations):\n",
    "            img = diffusion_step(img)\n",
    "        return img\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Smoothing method not implemented: {method}\")\n",
    "\n",
    "\n",
    "def get_grid_bounds(df):\n",
    "    x_min, x_max = int(df[\"posx\"].min()), int(df[\"posx\"].max())\n",
    "    y_min, y_max = int(df[\"posy\"].min()), int(df[\"posy\"].max())\n",
    "    grid_shape = (y_max - y_min + 1, x_max - x_min + 1)\n",
    "    return x_min, y_min, grid_shape\n",
    "\n",
    "\n",
    "# Smoothing function for a single dataframe\n",
    "def smooth_subset(subset_df, x_min, y_min, grid_shape):\n",
    "    smoothed_subset = pd.DataFrame(index=subset_df.index)\n",
    "\n",
    "    for feature in feature_list:\n",
    "        # Initialize grid with NaNs\n",
    "        grid_z = np.full(grid_shape, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Map each data point to the grid\n",
    "        for _, row in subset_df.iterrows():\n",
    "            x_idx = int(row[\"posx\"]) - x_min\n",
    "            y_idx = int(row[\"posy\"]) - y_min\n",
    "            grid_z[y_idx, x_idx] = row[feature]\n",
    "\n",
    "        # Interpolate missing values\n",
    "        yy, xx = np.indices(grid_z.shape)\n",
    "        valid_mask = ~np.isnan(grid_z)\n",
    "\n",
    "        if np.any(~valid_mask):\n",
    "            interpolator = NearestNDInterpolator(\n",
    "                np.column_stack((yy[valid_mask], xx[valid_mask])),\n",
    "                grid_z[valid_mask]\n",
    "            )\n",
    "            grid_z = interpolator(yy, xx)\n",
    "\n",
    "        # Apply feature-specific smoothing\n",
    "        methods = smoothing_config.get(feature,\n",
    "                                       'median')  # Get the designed methods, if None select defaul 'median' method\n",
    "        if isinstance(methods, list):\n",
    "            for method in methods:\n",
    "                grid_z = apply_smoothing(grid_z, method=method)\n",
    "        else:\n",
    "            grid_z = apply_smoothing(grid_z, method=methods)\n",
    "\n",
    "        # Map smoothed grid back to DataFrame\n",
    "        smoothed_subset[feature] = [\n",
    "            grid_z[int(row[\"posy\"]) - y_min, int(row[\"posx\"]) - x_min]\n",
    "            for _, row in subset_df.iterrows()\n",
    "        ]\n",
    "\n",
    "    # Add back metadata columns\n",
    "    smoothed_subset[['label', 'posx', 'posy']] = subset_df[['label', 'posx', 'posy']]\n",
    "    return smoothed_subset\n",
    "\n",
    "\n",
    "if smoothing_config is None:\n",
    "    smoothing_config = {feature: 'median' for feature in feature_list}\n",
    "\n",
    "# Compute grid bounds and smooth each subset\n",
    "test_x_min, test_y_min, test_grid_shape = get_grid_bounds(data_test)\n",
    "train_x_min, train_y_min, train_grid_shape = get_grid_bounds(data_train)\n",
    "val_x_min, val_y_min, val_grid_shape = get_grid_bounds(data_validation)\n",
    "\n",
    "# Smooth each subset SEPARATELY\n",
    "smoothed_test = smooth_subset(data_test, test_x_min, test_y_min, test_grid_shape)\n",
    "smoothed_train = smooth_subset(data_train, train_x_min, train_y_min, train_grid_shape)\n",
    "smoothed_validation = smooth_subset(data_validation, val_x_min, val_y_min, val_grid_shape)\n",
    "\n",
    "smoothed_df = pd.concat([smoothed_test, smoothed_train],\n",
    "                        ignore_index=True)  # For visualization in the next sections only"
   ],
   "id": "99d148d49061a836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DB SPLITTING",
   "id": "4b301ca0f0f71e01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "# Display class distribution\n",
    "X = smoothed_df[feature_list + [\"posx\", \"posy\"]]\n",
    "y = smoothed_df['label']\n",
    "\n",
    "# train_df = pd.concat([train_df1, train_df2], ignore_index=True)\n",
    "# smoothed_train = pd.concat([smoothed_train1, smoothed_train2], ignore_index=True)\n",
    "\n",
    "# Training distribution:\n",
    "class_distribution = Counter(smoothed_train['label'])\n",
    "print(\"Class distribution in the dataset:\")\n",
    "for label, count in sorted(class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y) * 100:.2f}%)\")\n",
    "\n",
    "# Test distribution:\n",
    "class_distribution = Counter(smoothed_test['label'])\n",
    "print(\"Class distribution in the dataset:\")\n",
    "for label, count in sorted(class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y) * 100:.2f}%)\")\n",
    "\n",
    "# Prepare data for classification\n",
    "X_train = smoothed_train[feature_list + [\"posx\", \"posy\"]]\n",
    "y_train = smoothed_train['label']\n",
    "\n",
    "X_test = smoothed_test[feature_list + [\"posx\", \"posy\"]]\n",
    "y_test = smoothed_test['label']\n",
    "\n",
    "X_validation = smoothed_validation[feature_list + [\"posx\", \"posy\"]]\n",
    "y_validation = smoothed_validation['label']\n",
    "\n",
    "# Create the figure and axes: 2 rows (train/test), then 3 histograms\n",
    "fig, axs = plt.subplots(2, 4, figsize=(22, 14), gridspec_kw={'width_ratios': [3, 1, 1, 1]})\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create consistent color map using turbo\n",
    "unique_labels = sorted(data_train['label'].unique())  # or union of train + test if needed\n",
    "palette_colors = sns.color_palette(\"turbo\", n_colors=len(unique_labels))\n",
    "label_color_dict = {label: color for label, color in zip(unique_labels, palette_colors)}\n",
    "\n",
    "# Plot train\n",
    "sns.scatterplot(\n",
    "    data=data_train,\n",
    "    x='posx',\n",
    "    y='posy',\n",
    "    hue='label',\n",
    "    palette=label_color_dict,  # Use fixed mapping\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_title(\"Train Set Distribution (posx vs posy)\")\n",
    "axs[0, 0].set_xlabel(\"Position X (posx)\")\n",
    "axs[0, 0].set_ylabel(\"Position Y (posy)\")\n",
    "axs[0, 0].legend(title='Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Plot test with same label-color mapping\n",
    "sns.scatterplot(\n",
    "    data=data_test,\n",
    "    x='posx',\n",
    "    y='posy',\n",
    "    hue='label',\n",
    "    palette=label_color_dict,  # Same dictionary ensures color consistency\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_title(\"Test Set Distribution (posx vs posy)\")\n",
    "axs[1, 0].set_xlabel(\"Position X (posx)\")\n",
    "axs[1, 0].set_ylabel(\"Position Y (posy)\")\n",
    "axs[1, 0].legend(title='Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# --- Histograms / Class Distribution Plots ---\n",
    "plot_class_distribution(smoothed_df['label'], axs[0, 1], \"Class Dist. (Entire)\")\n",
    "plot_class_distribution(y_train, axs[0, 2], \"Class Dist. (Train)\")\n",
    "plot_class_distribution(y_test, axs[0, 3], \"Class Dist. (Test)\")\n",
    "\n",
    "# Hide the unused bottom row histograms\n",
    "for ax in axs[1, 1:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # Drop posx and posy columns from the training and testing sets after plotting\n",
    "# X_train = X_train.drop(columns=['posx', 'posy'])\n",
    "# X_test = X_test.drop(columns=['posx', 'posy'])"
   ],
   "id": "934212b578e97c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Binary Classifier",
   "id": "25ce08865461ab20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_train1 = StandardScaler()\n",
    "scaler_train2 = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "X_train_selected = X_train[feature_list]\n",
    "X_test_selected = X_test[feature_list]\n",
    "X_validation_selected = X_validation[feature_list]\n",
    "\n",
    "# X_train_selected_1 = X_train_selected[X_train[\"posy\"] <= 140]\n",
    "# X_train_selected_2 = X_train_selected[X_train[\"posy\"] > 140]\n",
    "\n",
    "X_train_scaled = scaler_train1.fit_transform(X_train_selected)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_list, index=X_train_selected.index)\n",
    "\n",
    "X_validation_scaled = scaler_train1.fit_transform(X_validation_selected)\n",
    "X_validation_scaled = pd.DataFrame(X_validation_scaled, columns=feature_list, index=X_validation_selected.index)\n",
    "\n",
    "# X_train_scaled2 = scaler_train2.fit_transform(X_train_selected_2)\n",
    "\n",
    "# X_train_scaled1 = pd.DataFrame(X_train_scaled1, columns=feature_list, index=X_train_selected_1.index)\n",
    "# X_train_scaled2 = pd.DataFrame(X_train_scaled2, columns=feature_list, index=X_train_selected_2.index)\n",
    "# X_train_scaled = pd.concat([X_train_scaled1, X_train_scaled2]).sort_index()\n",
    "\n",
    "X_test_scaled = scaler_test.fit_transform(X_test_selected)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_list, index=X_test_selected.index)"
   ],
   "id": "9b855847b244c914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "def calculate_mutual_info(X_data, y_data, feature_list, random_state=42):\n",
    "    \"\"\"Calculate mutual information scores for features.\"\"\"\n",
    "    return mutual_info_classif(X_data[feature_list], y_data, random_state=random_state)\n",
    "\n",
    "\n",
    "def calculate_wasserstein_distances(train_data, validation_data, feature_list):\n",
    "    \"\"\"Calculate Wasserstein distance between train and validation for each feature.\"\"\"\n",
    "    distances = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        distance = wasserstein_distance(train_data[feature], validation_data[feature])\n",
    "        distances.append({'feature': feature, 'wasserstein_distance': distance})\n",
    "\n",
    "    return pd.DataFrame(distances)\n",
    "\n",
    "\n",
    "def plot_feature_importance(mi_df, distance_df, figsize=(24, 9)):\n",
    "    \"\"\"Plot mutual information and Wasserstein distance for features.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, sharey=True)\n",
    "\n",
    "    # Ensure both dataframes have the same feature ordering\n",
    "    # Sort by mutual information scores\n",
    "    mi_df = mi_df.sort_values('smoothed', ascending=True)\n",
    "\n",
    "    # Merge with distance_df to maintain the same order\n",
    "    merged_df = mi_df[['feature']].merge(distance_df, on='feature')\n",
    "\n",
    "    # Plot Mutual Information\n",
    "    bar_width = 0.45\n",
    "    y_positions = np.arange(len(mi_df))\n",
    "    ax = axes[0]\n",
    "\n",
    "    ax.barh(y_positions, mi_df['smoothed'], height=bar_width, color='blue',\n",
    "            alpha=0.6, label='Train')\n",
    "    ax.barh(y_positions + bar_width, mi_df['test'], height=bar_width, color='green',\n",
    "            alpha=0.6, label='Validation')\n",
    "\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(mi_df['feature'])\n",
    "    ax.set_title('Mutual Information Scores', fontsize=16)\n",
    "    ax.set_xlabel('Mutual Info Score', fontsize=12)\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend()\n",
    "\n",
    "    # Plot Wasserstein Distance - use the merged dataframe to keep order consistent\n",
    "    sns.barplot(x='wasserstein_distance', y='feature', data=merged_df,\n",
    "                palette='mako', ax=axes[1], hue='feature', legend=False)\n",
    "    axes[1].set_title('Train vs Test Wasserstein Distance', fontsize=16)\n",
    "    axes[1].set_xlabel('Distance', fontsize=12)\n",
    "    axes[1].set_ylabel('')\n",
    "    axes[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def select_features(mi_df, distance_df, mi_threshold=0.5, distance_threshold=0.12):\n",
    "    \"\"\"Select features based on mutual information and Wasserstein distance thresholds.\"\"\"\n",
    "    combined_df = mi_df.merge(distance_df, on='feature')\n",
    "\n",
    "    selected_features = combined_df[\n",
    "        (combined_df['smoothed'] > mi_threshold) &\n",
    "        (combined_df['test'] > mi_threshold) &\n",
    "        (combined_df['wasserstein_distance'] < distance_threshold)\n",
    "        ]\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def main(X_train_scaled, y_train, X_validation_scaled, y_validation, feature_list, selected_labels, mi_threshold=0.5,\n",
    "         distance_threshold=0.1):\n",
    "    \"\"\"Main function to perform feature selection analysis.\"\"\"\n",
    "    # Calculate mutual information for train and validation sets\n",
    "    mi_scores_train = calculate_mutual_info(X_train_scaled, y_train, feature_list)\n",
    "    mi_scores_val = calculate_mutual_info(X_validation_scaled, y_validation, feature_list)\n",
    "\n",
    "    # Create DataFrame for mutual information scores\n",
    "    mi_df = pd.DataFrame({\n",
    "        'feature': feature_list,\n",
    "        'smoothed': mi_scores_train,\n",
    "        'test': mi_scores_val,\n",
    "    }).sort_values('smoothed', ascending=True)\n",
    "\n",
    "    train_mask = y_train.isin(selected_labels)\n",
    "    X_train_filtered = X_train_scaled[train_mask]\n",
    "\n",
    "    # Filter validation data\n",
    "    test_mask = y_validation.isin(selected_labels)\n",
    "    X_val_filtered = X_validation_scaled[test_mask]\n",
    "\n",
    "    # Use the filtered data for distance calculation\n",
    "    distance_df = calculate_wasserstein_distances(\n",
    "        X_train_filtered, X_val_filtered, feature_list\n",
    "    )\n",
    "\n",
    "    # Plot feature importance\n",
    "    plot_feature_importance(mi_df, distance_df)\n",
    "    plt.show()\n",
    "\n",
    "    # Select features based on thresholds\n",
    "    selected = select_features(mi_df, distance_df, mi_threshold, distance_threshold)\n",
    "\n",
    "    # Output selected features\n",
    "    print(f\"✅ Features with MI (train & validation > {mi_threshold}) and \"\n",
    "          f\"Wasserstein < {distance_threshold}:\")\n",
    "    print(selected['feature'].tolist())\n",
    "\n",
    "    return selected['feature'].tolist()\n",
    "\n",
    "\n",
    "selected_features = main(\n",
    "    X_train_scaled=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_validation_scaled=X_validation_scaled,\n",
    "    y_validation=y_validation,\n",
    "    feature_list=feature_list,\n",
    "    selected_labels=[2, 3, 4, 5],\n",
    "    mi_threshold=0.53,\n",
    "    distance_threshold=0.08\n",
    ")"
   ],
   "id": "61fceab48729bb84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wasserstein_distance, ks_2samp, entropy\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def calculate_mutual_info(X_data, y_data, feature_list, random_state=42):\n",
    "    \"\"\"Calculate mutual information scores for features.\"\"\"\n",
    "    return mutual_info_classif(X_data[feature_list], y_data, random_state=random_state)\n",
    "\n",
    "\n",
    "def calculate_wasserstein_distances(train_data, validation_data, feature_list):\n",
    "    \"\"\"Calculate Wasserstein distance between train and validation for each feature.\"\"\"\n",
    "    distances = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        distance = wasserstein_distance(train_data[feature], validation_data[feature])\n",
    "        distances.append({'feature': feature, 'wasserstein_distance': distance})\n",
    "\n",
    "    return pd.DataFrame(distances)\n",
    "\n",
    "\n",
    "def jensen_shannon_distance(p, q):\n",
    "    \"\"\"Calculate Jensen-Shannon distance between two distributions.\"\"\"\n",
    "    # Convert to probability distributions\n",
    "    p = np.asarray(p) / np.sum(p)\n",
    "    q = np.asarray(q) / np.sum(q)\n",
    "\n",
    "    # Calculate M\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # Calculate JS divergence\n",
    "    js_divergence = 0.5 * (entropy(p, m) + entropy(q, m))\n",
    "\n",
    "    # Convert to distance (square root of divergence)\n",
    "    return np.sqrt(js_divergence)\n",
    "\n",
    "\n",
    "def calculate_distribution_metrics(train_data, validation_data, feature_list):\n",
    "    \"\"\"Calculate multiple distribution metrics between train and validation sets.\"\"\"\n",
    "    metrics = []\n",
    "\n",
    "    for feature in feature_list:\n",
    "        # Wasserstein distance (Earth Mover's Distance)\n",
    "        w_distance = wasserstein_distance(train_data[feature], validation_data[feature])\n",
    "\n",
    "        # Kolmogorov-Smirnov test\n",
    "        ks_stat, ks_pval = ks_2samp(train_data[feature], validation_data[feature])\n",
    "\n",
    "        # Jensen-Shannon distance\n",
    "        # First, we need to create histograms to compare distributions\n",
    "        hist_bins = 30\n",
    "        train_hist, _ = np.histogram(train_data[feature], bins=hist_bins, density=True)\n",
    "        val_hist, _ = np.histogram(validation_data[feature], bins=hist_bins, density=True)\n",
    "\n",
    "        # Add small epsilon to avoid divide by zero issues\n",
    "        train_hist = train_hist + 1e-10\n",
    "        val_hist = val_hist + 1e-10\n",
    "\n",
    "        js_dist = jensen_shannon_distance(train_hist, val_hist)\n",
    "\n",
    "        metrics.append({\n",
    "            'feature': feature,\n",
    "            'wasserstein_distance': w_distance,\n",
    "            'ks_statistic': ks_stat,\n",
    "            'ks_pvalue': ks_pval,\n",
    "            'jensen_shannon_distance': js_dist\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "def calculate_class_distribution_metrics(X_train, y_train, X_validation, y_validation, feature_list, selected_classes):\n",
    "    \"\"\"Calculate distribution metrics for each selected class.\"\"\"\n",
    "    class_metrics = {}\n",
    "\n",
    "    for cls in selected_classes:\n",
    "        # Filter data for this class\n",
    "        X_train_cls = X_train[y_train == cls]\n",
    "        X_val_cls = X_validation[y_validation == cls]\n",
    "\n",
    "        # Calculate metrics for this class\n",
    "        metrics_df = calculate_distribution_metrics(X_train_cls, X_val_cls, feature_list)\n",
    "        class_metrics[cls] = metrics_df\n",
    "\n",
    "    return class_metrics\n",
    "\n",
    "\n",
    "def plot_feature_importance(mi_df, metrics_df, figsize=(24, 12)):\n",
    "    \"\"\"Plot mutual information and distribution metrics for features.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "\n",
    "    # Ensure both dataframes have the same feature ordering\n",
    "    mi_df = mi_df.sort_values('smoothed', ascending=False)\n",
    "\n",
    "    # Merge to maintain the same order\n",
    "    merged_df = mi_df[['feature']].merge(metrics_df, on='feature')\n",
    "\n",
    "    # Plot Mutual Information\n",
    "    sns.barplot(x='smoothed', y='feature', data=mi_df.head(15),\n",
    "                color='blue', alpha=0.7, ax=axes[0, 0])\n",
    "    sns.barplot(x='test', y='feature', data=mi_df.head(15),\n",
    "                color='green', alpha=0.7, ax=axes[0, 1])\n",
    "\n",
    "    axes[0, 0].set_title('Mutual Information (Train)', fontsize=14)\n",
    "    axes[0, 1].set_title('Mutual Information (Validation)', fontsize=14)\n",
    "\n",
    "    # Plot distribution metrics\n",
    "    sns.barplot(x='wasserstein_distance', y='feature', data=merged_df.head(15),\n",
    "                palette='mako', ax=axes[1, 0])\n",
    "    sns.barplot(x='jensen_shannon_distance', y='feature', data=merged_df.head(15),\n",
    "                palette='rocket', ax=axes[1, 1])\n",
    "\n",
    "    axes[1, 0].set_title('Wasserstein Distance (Train vs Validation)', fontsize=14)\n",
    "    axes[1, 1].set_title('Jensen-Shannon Distance (Train vs Validation)', fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_class_distribution_metrics(class_metrics, selected_classes, top_features=10, figsize=(15, 10)):\n",
    "    \"\"\"Plot distribution metrics across classes for top features.\"\"\"\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "\n",
    "    # Get the top features based on average Wasserstein distance across classes\n",
    "    feature_avg_metrics = {}\n",
    "\n",
    "    for feature in class_metrics[selected_classes[0]]['feature'].unique():\n",
    "        feature_metrics = []\n",
    "        for cls in selected_classes:\n",
    "            cls_df = class_metrics[cls]\n",
    "            feature_row = cls_df[cls_df['feature'] == feature]\n",
    "            if not feature_row.empty:\n",
    "                feature_metrics.append(feature_row['wasserstein_distance'].values[0])\n",
    "\n",
    "        feature_avg_metrics[feature] = np.mean(feature_metrics)\n",
    "\n",
    "    # Sort features by average Wasserstein distance\n",
    "    sorted_features = sorted(feature_avg_metrics.items(), key=lambda x: x[1])\n",
    "    top_features_list = [f[0] for f in sorted_features[:top_features]]\n",
    "\n",
    "    # Create data for plotting\n",
    "    for feature in top_features_list:\n",
    "        for cls in selected_classes:\n",
    "            cls_df = class_metrics[cls]\n",
    "            feature_row = cls_df[cls_df['feature'] == feature]\n",
    "\n",
    "            if not feature_row.empty:\n",
    "                plot_data.append({\n",
    "                    'feature': feature,\n",
    "                    'class': cls,\n",
    "                    'wasserstein_distance': feature_row['wasserstein_distance'].values[0],\n",
    "                    'jensen_shannon_distance': feature_row['jensen_shannon_distance'].values[0]\n",
    "                })\n",
    "\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    # Create plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # Plot Wasserstein distance by class\n",
    "    sns.barplot(x='wasserstein_distance', y='feature', hue='class',\n",
    "                data=plot_df, ax=axes[0], palette='viridis')\n",
    "    axes[0].set_title('Wasserstein Distance by Class', fontsize=14)\n",
    "    axes[0].legend(title='Class')\n",
    "\n",
    "    # Plot Jensen-Shannon distance by class\n",
    "    sns.barplot(x='jensen_shannon_distance', y='feature', hue='class',\n",
    "                data=plot_df, ax=axes[1], palette='viridis')\n",
    "    axes[1].set_title('Jensen-Shannon Distance by Class', fontsize=14)\n",
    "    axes[1].legend(title='Class')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualize_feature_distributions(X_train, y_train, X_validation, y_validation,\n",
    "                                    selected_features, selected_classes,\n",
    "                                    n_features=4, figsize=(16, 12)):\n",
    "    \"\"\"Visualize the distributions of selected features across classes.\"\"\"\n",
    "    if len(selected_features) > n_features:\n",
    "        selected_features = selected_features[:n_features]\n",
    "\n",
    "    fig, axes = plt.subplots(len(selected_features), len(selected_classes), figsize=figsize)\n",
    "\n",
    "    for i, feature in enumerate(selected_features):\n",
    "        for j, cls in enumerate(selected_classes):\n",
    "            ax = axes[i, j] if len(selected_features) > 1 else axes[j]\n",
    "\n",
    "            # Filter data for the class\n",
    "            train_data = X_train[y_train == cls][feature]\n",
    "            val_data = X_validation[y_validation == cls][feature]\n",
    "\n",
    "            # Plot distributions\n",
    "            sns.histplot(train_data, kde=True, color='blue', alpha=0.5,\n",
    "                         ax=ax, label='Train', stat='density')\n",
    "            sns.histplot(val_data, kde=True, color='green', alpha=0.5,\n",
    "                         ax=ax, label='Validation', stat='density')\n",
    "\n",
    "            # Calculate Wasserstein distance for this feature and class\n",
    "            w_dist = wasserstein_distance(train_data, val_data)\n",
    "\n",
    "            ax.set_title(f\"Class {cls}, Feature: {feature}\\nWasserstein = {w_dist:.4f}\", fontsize=10)\n",
    "\n",
    "            if i == 0:\n",
    "                ax.legend()\n",
    "\n",
    "            if i == len(selected_features) - 1:\n",
    "                ax.set_xlabel(feature)\n",
    "            else:\n",
    "                ax.set_xlabel('')\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_ylabel('Density')\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def select_features_advanced(mi_df, metrics_df, class_metrics, selected_classes,\n",
    "                             mi_threshold=0.5, wasserstein_threshold=0.12,\n",
    "                             jensen_shannon_threshold=0.3,\n",
    "                             max_class_deviation=0.05):\n",
    "    \"\"\"\n",
    "    Select features based on multiple criteria:\n",
    "    1. High mutual information in both train and validation\n",
    "    2. Low distribution distances between train and validation\n",
    "    3. Consistent distribution across all selected classes\n",
    "    \"\"\"\n",
    "    # Step 1: Filter by mutual information\n",
    "    mi_selected = mi_df[(mi_df['smoothed'] > mi_threshold) &\n",
    "                        (mi_df['test'] > mi_threshold)]\n",
    "\n",
    "    # Step 2: Filter by overall distribution metrics\n",
    "    dist_selected = metrics_df[(metrics_df['wasserstein_distance'] < wasserstein_threshold) &\n",
    "                               (metrics_df['jensen_shannon_distance'] < jensen_shannon_threshold)]\n",
    "\n",
    "    # Combine the filters\n",
    "    combined_selected = mi_selected[['feature']].merge(dist_selected[['feature']], on='feature')\n",
    "\n",
    "    # Step 3: Filter by class consistency\n",
    "    consistent_features = []\n",
    "\n",
    "    for feature in combined_selected['feature']:\n",
    "        # Check if feature is consistent across all classes\n",
    "        class_wasserstein_values = []\n",
    "        class_js_values = []\n",
    "\n",
    "        for cls in selected_classes:\n",
    "            cls_df = class_metrics[cls]\n",
    "            feature_row = cls_df[cls_df['feature'] == feature]\n",
    "\n",
    "            if not feature_row.empty:\n",
    "                class_wasserstein_values.append(feature_row['wasserstein_distance'].values[0])\n",
    "                class_js_values.append(feature_row['jensen_shannon_distance'].values[0])\n",
    "\n",
    "        # Calculate coefficient of variation (std / mean) as a measure of consistency\n",
    "        wasserstein_cv = np.std(class_wasserstein_values) / (np.mean(class_wasserstein_values) + 1e-10)\n",
    "        js_cv = np.std(class_js_values) / (np.mean(class_js_values) + 1e-10)\n",
    "\n",
    "        # Check if the feature is consistent across classes\n",
    "        if wasserstein_cv < max_class_deviation and js_cv < max_class_deviation:\n",
    "            consistent_features.append(feature)\n",
    "\n",
    "    # Create final selection\n",
    "    final_selection = combined_selected[combined_selected['feature'].isin(consistent_features)]\n",
    "\n",
    "    return final_selection['feature'].tolist()\n",
    "\n",
    "\n",
    "def main(X_train_scaled, y_train, X_validation_scaled, y_validation, feature_list,\n",
    "         selected_classes, mi_threshold=0.5, wasserstein_threshold=0.1,\n",
    "         jensen_shannon_threshold=0.3, class_deviation_threshold=0.3):\n",
    "    \"\"\"Enhanced main function to perform feature selection analysis.\"\"\"\n",
    "    # print(f\"Analyzing feature distributions for classes: {selected_classes}\")\n",
    "\n",
    "    # Filter data for selected classes\n",
    "    train_mask = y_train.isin(selected_classes)\n",
    "    X_train_filtered = X_train_scaled[train_mask]\n",
    "    y_train_filtered = y_train[train_mask]\n",
    "\n",
    "    test_mask = y_validation.isin(selected_classes)\n",
    "    X_val_filtered = X_validation_scaled[test_mask]\n",
    "    y_val_filtered = y_validation[test_mask]\n",
    "\n",
    "    # Calculate mutual information for train and validation sets\n",
    "    mi_scores_train = calculate_mutual_info(X_train_filtered, y_train_filtered, feature_list)\n",
    "    mi_scores_val = calculate_mutual_info(X_val_filtered, y_val_filtered, feature_list)\n",
    "\n",
    "    # Create DataFrame for mutual information scores\n",
    "    mi_df = pd.DataFrame({\n",
    "        'feature': feature_list,\n",
    "        'smoothed': mi_scores_train,\n",
    "        'test': mi_scores_val,\n",
    "    })\n",
    "\n",
    "    # Calculate overall distribution metrics\n",
    "    metrics_df = calculate_distribution_metrics(X_train_filtered, X_val_filtered, feature_list)\n",
    "\n",
    "    # Calculate class-specific distribution metrics\n",
    "    class_metrics = calculate_class_distribution_metrics(\n",
    "        X_train_filtered, y_train_filtered,\n",
    "        X_val_filtered, y_val_filtered,\n",
    "        feature_list, selected_classes\n",
    "    )\n",
    "\n",
    "    # # Plot feature importance\n",
    "    # print(\"Plotting overall feature importance...\")\n",
    "    # plot_feature_importance(mi_df, metrics_df)\n",
    "    # plt.show()\n",
    "    #\n",
    "    # # Plot class-specific metrics\n",
    "    # print(\"Plotting class-specific distribution metrics...\")\n",
    "    # plot_class_distribution_metrics(class_metrics, selected_classes)\n",
    "    # plt.show()\n",
    "\n",
    "    # Select features based on enhanced criteria\n",
    "    selected_features = select_features_advanced(\n",
    "        mi_df, metrics_df, class_metrics, selected_classes,\n",
    "        mi_threshold, wasserstein_threshold,\n",
    "        jensen_shannon_threshold, class_deviation_threshold\n",
    "    )\n",
    "    #\n",
    "    # # Visualize distributions of selected features\n",
    "    # print(\"Visualizing distributions of selected features across classes...\")\n",
    "    # if len(selected_features) > 0:\n",
    "    #     visualize_feature_distributions(\n",
    "    #         X_train_filtered, y_train_filtered,\n",
    "    #         X_val_filtered, y_val_filtered,\n",
    "    #         selected_features, selected_classes\n",
    "    #     )\n",
    "    #     plt.show()\n",
    "    #\n",
    "    # # Output selected features\n",
    "    # print(f\"\\n✅ Selected Features ({len(selected_features)}):\")\n",
    "    # print(f\"  - MI threshold: {mi_threshold}\")\n",
    "    # print(f\"  - Wasserstein threshold: {wasserstein_threshold}\")\n",
    "    # print(f\"  - Jensen-Shannon threshold: {jensen_shannon_threshold}\")\n",
    "    # print(f\"  - Class deviation threshold: {class_deviation_threshold}\")\n",
    "    #\n",
    "    # if len(selected_features) > 0:\n",
    "    #     for i, feature in enumerate(selected_features, 1):\n",
    "    #         print(f\"  {i}. {feature}\")\n",
    "    # else:\n",
    "    #     print(\"  No features met all criteria. Consider relaxing thresholds.\")\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "# Example usage\n",
    "selected_features = main(\n",
    "    X_train_scaled=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_validation_scaled=X_validation_scaled,\n",
    "    y_validation=y_validation,\n",
    "    feature_list=feature_list_3,\n",
    "    selected_classes=[2, 3, 4, 5],\n",
    "    mi_threshold=0.3,\n",
    "    wasserstein_threshold=0.275,\n",
    "    jensen_shannon_threshold=0.25,\n",
    "    class_deviation_threshold=110\n",
    ")"
   ],
   "id": "f64bd09dc97fb9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def find_best_smoothing_params(\n",
    "        df,\n",
    "        features_to_smooth,\n",
    "        class_label_col,\n",
    "        bandwidth_values,\n",
    "        center_emphasis_values,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each (bw,ce) in the grid, smooth the df, then compute\n",
    "    silhouette_score on the smoothed feature matrix (only the smoothed\n",
    "    features), using the true class labels in `class_label_col`.\n",
    "    Returns a DataFrame of scores and the best (bw, ce).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    true_labels = df[class_label_col].values\n",
    "\n",
    "    for bw in tqdm(bandwidth_values, desc=\"bandwidth\"):\n",
    "        for ce in center_emphasis_values:\n",
    "            # 1) smooth\n",
    "            selected_features = main(\n",
    "                X_train_scaled=X_train_scaled,\n",
    "                y_train=y_train,\n",
    "                X_validation_scaled=X_validation_scaled,\n",
    "                y_validation=y_validation,\n",
    "                feature_list=feature_list_3,\n",
    "                selected_classes=[2, 3, 4, 5],\n",
    "                mi_threshold=0.3,\n",
    "                wasserstein_threshold=bw,\n",
    "                jensen_shannon_threshold=ce,\n",
    "                class_deviation_threshold=110\n",
    "            )\n",
    "\n",
    "            X = df[selected_features].values\n",
    "\n",
    "            # 2) silhouette (note: requires at least 2 points per class)\n",
    "            try:\n",
    "                score = silhouette_score(X, true_labels)\n",
    "            except ValueError:\n",
    "                score = np.nan\n",
    "\n",
    "            results.append({\n",
    "                'w_th': bw,\n",
    "                'js_th': ce,\n",
    "                'n_features': len(selected_features),\n",
    "                'silhouette': score\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # pick the best\n",
    "    best = results_df.loc[results_df['silhouette'].idxmax()]\n",
    "    return results_df, best['w_th'], best['js_th'], best['silhouette']\n",
    "\n",
    "bw_vals =  np.arange(0, 0.3, 0.025).tolist()\n",
    "ce_vals = np.arange(0, 0.3, 0.025).tolist()\n",
    "features = [f for f in feature_list if f not in ['posx', 'posy', 'label', 'class']]\n",
    "\n",
    "df_all = pd.concat([X_train_scaled, X_validation_scaled], axis=0, ignore_index=True)\n",
    "df_all['class'] = pd.concat([y_train, y_validation], axis=0, ignore_index=True)\n",
    "\n",
    "# df_all = hard_spots_validation\n",
    "# df_all['class'] = y_validation_hard\n",
    "\n",
    "results_df, best_bw, best_ce, best_score = find_best_smoothing_params(\n",
    "    df=df_all,\n",
    "    features_to_smooth=features,\n",
    "    class_label_col='class',\n",
    "    bandwidth_values=bw_vals,\n",
    "    center_emphasis_values=ce_vals\n",
    ")\n",
    "\n",
    "print(\"Best params:\", best_bw, best_ce, \". silhouette:\", best_score)\n",
    "results_df = results_df.dropna()\n",
    "\n",
    "# keeps the best silhouette score for equal number of features\n",
    "results_df = results_df.loc[results_df.groupby('n_features')['silhouette'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "results_df"
   ],
   "id": "fb258a23a944670d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_df = results_df.dropna()\n",
    "\n",
    "# keeps the best silhouette score for equal number of features\n",
    "results_df = results_df.loc[results_df.groupby('n_features')['silhouette'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "results_df"
   ],
   "id": "ea4fcf8f588974d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "feature_list = selected_features",
   "id": "7208d6a889a59a8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_features\n",
    "\n",
    "X_train_nz = X_train_scaled.copy()\n",
    "X_train_nz[\"label\"] = y_train\n",
    "X_train_nz[\"posy\"] = X_train[\"posy\"]\n",
    "X_train_nz[\"posx\"] = X_train[\"posx\"]\n",
    "\n",
    "X_test_new_nz = X_test_scaled.copy()\n",
    "X_test_new_nz[\"label\"] = y_test\n",
    "X_test_new_nz[\"posx\"] = X_test[\"posx\"]\n",
    "X_test_new_nz[\"posy\"] = X_test[\"posy\"]\n",
    "\n",
    "X_val_new_nz = X_validation_scaled.copy()\n",
    "X_val_new_nz[\"label\"] = y_validation\n",
    "X_val_new_nz[\"posx\"] = X_validation[\"posx\"]\n",
    "X_val_new_nz[\"posy\"] = X_validation[\"posy\"]\n",
    "\n",
    "# plot_features(X_train_nz, X_test_new_nz, feature_list)"
   ],
   "id": "265b44dc61be676e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create dataset with selected features (excluding posx, posy)\n",
    "# X_train_selected = X_train[feature_list]\n",
    "# X_test_selected = X_test[feature_list]\n",
    "\n",
    "X_train_selected = X_train_scaled[feature_list]\n",
    "X_test_selected = X_test_scaled[feature_list]\n",
    "X_validation_selected = X_validation_scaled[feature_list]\n",
    "\n",
    "# Convert labels to binary classification (0 vs all)\n",
    "y_train_binary = np.where(y_train == 0, 0, 1)\n",
    "y_test_binary = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "# Apply ADASYN for class imbalance handling\n",
    "adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=10)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train_binary)\n",
    "# X_train_adasyn, y_train_multi = X_train_selected, y_train\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model on binary data\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = rf_model.predict(X_test_selected)\n",
    "\n",
    "y_validation_pred = rf_model.predict(X_validation_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_binary, y_test_pred, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_binary, y_test_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_binary, y_test_pred)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "print(f\"\\nTrain Accuracy: {train_accuracy:.3f}, Train Balanced Accuracy: {train_balanced_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}, Test Balanced Accuracy: {test_balanced_acc:.3f}\")\n",
    "\n",
    "\n",
    "# Function to create and plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.nan_to_num(cm_norm)  # Replace NaN with 0\n",
    "\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.3f', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1], ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_binary, y_test_pred, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "376e50309c20825d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hard_spots_test_index = y_test_pred == 1\n",
    "hard_spots_test = X_test_new_nz[hard_spots_test_index]\n",
    "y_test_hard = y_test[hard_spots_test_index]\n",
    "\n",
    "hard_spots_val_index = y_validation_pred == 1\n",
    "hard_spots_validation = X_val_new_nz[hard_spots_val_index]\n",
    "y_validation_hard = y_validation[hard_spots_val_index]\n",
    "\n",
    "# y_train_pred = rf_model.predict(X_train[feature_list])\n",
    "hard_spots_train_index = y_train != 0\n",
    "hard_spots_train = X_train_nz[hard_spots_train_index]\n",
    "y_train_hard = y_train[hard_spots_train_index]"
   ],
   "id": "fa381afac4490ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def reverse_weighted_smooth(\n",
    "        df,\n",
    "        features_to_smooth,\n",
    "        bandwidth=4.0,\n",
    "        center_emphasis=3.0,\n",
    "        eps=2.0,\n",
    "        min_samples=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Smooth each feature in `features_to_smooth` by Gaussian-weighted averaging,\n",
    "    but boost the DBSCAN cluster-center’s weight by `center_emphasis` in every\n",
    "    point’s smoothing computation.\n",
    "    \"\"\"\n",
    "    df_smoothed = df.copy()\n",
    "    coords = df[['posx', 'posy']].values\n",
    "\n",
    "    # 1) DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)\n",
    "    labels = clustering.labels_\n",
    "    unique_labels = [lbl for lbl in np.unique(labels) if lbl != -1]\n",
    "\n",
    "    # 2) Identify cluster centers\n",
    "    center_indices = []\n",
    "    center_indices_by_label = {}\n",
    "    for lbl in unique_labels:\n",
    "        mask = (labels == lbl)\n",
    "        pts = coords[mask]\n",
    "        centroid = pts.mean(axis=0)\n",
    "        # find the member closest to centroid\n",
    "        distances = ((pts - centroid) ** 2).sum(axis=1)\n",
    "        member_indices = np.where(mask)[0]\n",
    "        center_idx = member_indices[np.argmin(distances)]\n",
    "        center_indices.append(center_idx)\n",
    "        center_indices_by_label[lbl] = center_idx\n",
    "\n",
    "    # 3) Smooth each feature\n",
    "    for feature in features_to_smooth:\n",
    "        if feature not in df.columns or feature in ['posx', 'posy', 'label']:\n",
    "            continue\n",
    "\n",
    "        orig = df[feature].values\n",
    "        sm = np.empty_like(orig, dtype=float)\n",
    "\n",
    "        for i in range(len(coords)):\n",
    "            # distances from point i to all points\n",
    "            dists = np.linalg.norm(coords - coords[i], axis=1)\n",
    "            w = np.exp(-0.5 * (dists / bandwidth) ** 2)\n",
    "\n",
    "            lbl = labels[i]\n",
    "            # if it belongs to a real cluster, boost its center’s weight\n",
    "            if lbl != -1:\n",
    "                center_idx = center_indices_by_label[lbl]\n",
    "                w[center_idx] *= center_emphasis\n",
    "\n",
    "            # normalize & compute weighted average\n",
    "            sm[i] = (w * orig).sum() / w.sum()\n",
    "\n",
    "        df_smoothed[feature] = sm\n",
    "\n",
    "    return df_smoothed, center_indices, labels\n",
    "\n",
    "\n",
    "def visualize_clusters_and_centers(df, center_indices, labels, ax, title):\n",
    "    \"\"\"\n",
    "    Scatterplot of (posx,posy) colored by DBSCAN label, with X’s at centers.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for idx, lbl in enumerate(unique_labels):\n",
    "        mask = (labels == lbl)\n",
    "        color = 'black' if lbl == -1 else colors[idx]\n",
    "        ax.scatter(\n",
    "            df.loc[mask, 'posx'], df.loc[mask, 'posy'],\n",
    "            c=[color], edgecolor='k', s=50, alpha=0.6\n",
    "        )\n",
    "\n",
    "    centers = df.iloc[center_indices][['posx', 'posy']].values\n",
    "    ax.scatter(\n",
    "        centers[:, 0], centers[:, 1],\n",
    "        c='red', marker='X', s=200, edgecolor='k'\n",
    "    )\n",
    "    ax.set_title(f'{title} with Cluster Centers')\n",
    "    ax.set_xlabel('posx')\n",
    "    ax.set_ylabel('posy')\n",
    "\n",
    "\n",
    "# --- USAGE EXAMPLE ---\n",
    "\n",
    "# Suppose `hard_spots_train` and `hard_spots_test` are your DataFrames,\n",
    "# and `feature_list` is e.g. list(df.columns).\n",
    "\n",
    "features_to_smooth = [f for f in feature_list if f not in ['posx', 'posy', 'label']]\n",
    "\n",
    "# Train set smoothing\n",
    "hard_spots_train_smoothed, train_center_idxs, train_labels = reverse_weighted_smooth(\n",
    "    hard_spots_train,\n",
    "    features_to_smooth,\n",
    "    bandwidth=2.0,\n",
    "    center_emphasis=2.0,  # ↑ increase for stronger central pull\n",
    "    eps=2.0,\n",
    "    min_samples=10\n",
    ")\n",
    "\n",
    "# Test set smoothing\n",
    "hard_spots_test_smoothed, test_center_idxs, test_labels = reverse_weighted_smooth(\n",
    "    hard_spots_test,\n",
    "    features_to_smooth,\n",
    "    bandwidth=2.0,\n",
    "    center_emphasis=2.0,\n",
    "    eps=2.0,\n",
    "    min_samples=10\n",
    ")\n",
    "\n",
    "hard_spots_validation_smoothed, validation_center_idxs, validation_labels = reverse_weighted_smooth(\n",
    "    hard_spots_validation,\n",
    "    features_to_smooth,\n",
    "    bandwidth=2.0,\n",
    "    center_emphasis=2.0,\n",
    "    eps=2.0,\n",
    "    min_samples=10\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "visualize_clusters_and_centers(\n",
    "    hard_spots_train_smoothed, train_center_idxs, train_labels, axes[0], \"Train\"\n",
    ")\n",
    "\n",
    "visualize_clusters_and_centers(\n",
    "    hard_spots_test_smoothed, test_center_idxs, test_labels, axes[1], \"Train: Smoothed\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Visualize the clusters and centers7\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "# visualize_clusters_and_centers(hard_spots_test, center_indices, labels, axes[1], \"test\")\n",
    "# visualize_clusters_and_centers(hard_spots_train, center_indices2, labels2, axes[0], \"train\")\n",
    "#\n",
    "\n",
    "# Plot the smoothing effect for comparison\n",
    "def plot_smoothing_effect(test_original, test_smooth, train_original, train_smoothed, feature):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "    # Plot original values\n",
    "    sc1 = axes[1][0].scatter(test_original['posx'], test_original['posy'],\n",
    "                             c=test_original[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[1][0].set_title(f\"Test: Original {feature}\")\n",
    "    axes[1][0].set_xlabel(\"posx\")\n",
    "    axes[1][0].set_ylabel(\"posy\")\n",
    "\n",
    "    sc1 = axes[0][0].scatter(train_original['posx'], train_original['posy'],\n",
    "                             c=train_original[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[0][0].set_title(f\"Train: Original {feature}\")\n",
    "    axes[0][0].set_xlabel(\"posx\")\n",
    "    axes[0][0].set_ylabel(\"posy\")\n",
    "\n",
    "    # Plot smoothed values\n",
    "    sc2 = axes[1][1].scatter(test_smooth['posx'], test_smooth['posy'],\n",
    "                             c=test_smooth[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[1][1].set_title(f\"Test: Smoothed {feature}\")\n",
    "    axes[1][1].set_xlabel(\"posx\")\n",
    "    axes[1][1].set_ylabel(\"posy\")\n",
    "\n",
    "    sc2 = axes[0][1].scatter(train_smoothed['posx'], train_smoothed['posy'],\n",
    "                             c=train_smoothed[feature], cmap='viridis',\n",
    "                             s=50, alpha=0.8)\n",
    "    axes[0][1].set_title(f\"Train: Smoothed {feature}\")\n",
    "    axes[0][1].set_xlabel(\"posx\")\n",
    "    axes[0][1].set_ylabel(\"posy\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for feature in features_to_smooth:\n",
    "    plot_smoothing_effect(hard_spots_test, hard_spots_test_smoothed, hard_spots_train, hard_spots_train_smoothed,\n",
    "                          feature)"
   ],
   "id": "2f21ffde98ecf84c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def find_best_smoothing_params(\n",
    "        df,\n",
    "        features_to_smooth,\n",
    "        class_label_col,\n",
    "        bandwidth_values,\n",
    "        center_emphasis_values,\n",
    "        eps=2.0,\n",
    "        min_samples=10\n",
    "):\n",
    "    \"\"\"\n",
    "    For each (bw,ce) in the grid, smooth the df, then compute\n",
    "    silhouette_score on the smoothed feature matrix (only the smoothed\n",
    "    features), using the true class labels in `class_label_col`.\n",
    "    Returns a DataFrame of scores and the best (bw, ce).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    true_labels = df[class_label_col].values\n",
    "\n",
    "    for bw in tqdm(bandwidth_values, desc=\"bandwidth\"):\n",
    "        for ce in center_emphasis_values:\n",
    "            # 1) smooth\n",
    "            sm_df, _, _ = reverse_weighted_smooth(\n",
    "                df, features_to_smooth,\n",
    "                bandwidth=bw,\n",
    "                center_emphasis=ce\n",
    "            )\n",
    "\n",
    "            X = sm_df[features_to_smooth].values\n",
    "\n",
    "            # 2) silhouette (note: requires at least 2 points per class)\n",
    "            try:\n",
    "                score = silhouette_score(X, true_labels)\n",
    "            except ValueError:\n",
    "                score = np.nan\n",
    "\n",
    "            results.append({\n",
    "                'bandwidth': bw,\n",
    "                'center_emphasis': ce,\n",
    "                'silhouette': score\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # pick the best\n",
    "    best = results_df.loc[results_df['silhouette'].idxmax()]\n",
    "    return results_df, best['bandwidth'], best['center_emphasis'], best['silhouette']\n",
    "\n",
    "\n",
    "bw_vals = [7, 8, 9, 10, 11, 12, 13]\n",
    "ce_vals = [0, 1.0, 2.0, 3]\n",
    "features = [f for f in feature_list if f not in ['posx', 'posy', 'label', 'class']]\n",
    "\n",
    "df_all = pd.concat([hard_spots_train, hard_spots_validation], axis=0, ignore_index=True)\n",
    "df_all['class'] = pd.concat([y_train, y_validation_hard], axis=0, ignore_index=True)\n",
    "\n",
    "# df_all = hard_spots_validation\n",
    "# df_all['class'] = y_validation_hard\n",
    "\n",
    "results_df, best_bw, best_ce, best_score = find_best_smoothing_params(\n",
    "    df=df_all,\n",
    "    features_to_smooth=features,\n",
    "    class_label_col='class',\n",
    "    bandwidth_values=bw_vals,\n",
    "    center_emphasis_values=ce_vals\n",
    ")\n",
    "\n",
    "print(\"Best params:\", best_bw, best_ce, \"– silhouette:\", best_score)"
   ],
   "id": "5a9c79cfe272a584",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_features(hard_spots_train_smoothed, hard_spots_test_smoothed, feature_list)",
   "id": "ea282789fcfed177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_list = ['Stiffness',\n",
    " 'Upstroke',\n",
    " 'Downstroke',\n",
    " 'time_to_max',\n",
    " 'loading_unloading_area_ratio',\n",
    " 'cubic_coefficient',\n",
    " 'quartic_coefficient',\n",
    " 'loading_nonlinearity' ]#, 'force_ratio_75_25']"
   ],
   "id": "b8f26fcd7114eca9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Full Classifier",
   "id": "b52a137be2c5df8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_confusion_matrix\n",
    "\n",
    "# test_index = y_test_pred == 1\n",
    "# X_test_new_nz = X_test_new[test_index]\n",
    "# y_test_nz = y_test[test_index]\n",
    "#\n",
    "# train_index = y_train != 0\n",
    "# X_train_nz = X_train[train_index]\n",
    "# y_train_nz = y_train[train_index]\n",
    "#\n",
    "# X_train_selected = X_train_nz[feature_list]\n",
    "# X_test_selected = X_test_new_nz[feature_list]  #X_test  --- X_test_new\n",
    "\n",
    "X_train_selected = hard_spots_train_smoothed[feature_list]\n",
    "X_test_selected = hard_spots_test_smoothed[feature_list]\n",
    "y_train_nz = y_train_hard\n",
    "y_test_nz = y_test_hard\n",
    "\n",
    "# Apply ADASYN for adaptive oversampling\n",
    "# adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5)\n",
    "# X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "X_train_adasyn, y_train_adasyn = X_train_selected, y_train_nz\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_nz = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_nz, y_test_pred_nz, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_nz, y_test_pred_nz, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4478eee696ff2186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from plotter import plot_confusion_matrix\n",
    "\n",
    "test_index = y_test_pred == 1\n",
    "X_test_new_nz = X_test_scaled[test_index]\n",
    "y_test_nz = y_test[test_index]\n",
    "\n",
    "train_index = y_train != 0\n",
    "X_train_nz = X_train_scaled[train_index]\n",
    "y_train_nz = y_train[train_index]\n",
    "\n",
    "X_train_selected = X_train_nz[feature_list]\n",
    "X_test_selected = X_test_new_nz[feature_list]  #X_test  --- X_test_new\n",
    "\n",
    "# X_train_selected = hard_spots_train_smoothed[feature_list]\n",
    "# X_test_selected = hard_spots_test_smoothed[feature_list]\n",
    "# y_train_nz = y_train_hard\n",
    "# y_test_nz = y_test_hard\n",
    "\n",
    "# Apply ADASYN for adaptive oversampling\n",
    "# adasyn = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5)\n",
    "# X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "X_train_adasyn, y_train_adasyn = X_train_selected, y_train_nz\n",
    "\n",
    "# Display new class distribution after ADASYN\n",
    "adasyn_class_distribution = Counter(y_train_adasyn)\n",
    "print(\"\\nClass distribution after ADASYN:\")\n",
    "for label, count in sorted(adasyn_class_distribution.items()):\n",
    "    print(f\"Label {label}: {count} samples ({count / len(y_train_adasyn) * 100:.2f}%)\")\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    class_weight=None,\n",
    "    random_state=42,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_adasyn, y_train_adasyn)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = rf_model.predict(X_train_adasyn)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_nz = rf_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test_nz, y_test_pred_nz, zero_division=0))\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_nz, y_test_pred_nz)\n",
    "train_accuracy = accuracy_score(y_train_adasyn, y_train_pred)\n",
    "train_balanced_acc = balanced_accuracy_score(y_train_adasyn, y_train_pred)\n",
    "\n",
    "# Create a figure with two subplots for the confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Plot confusion matrices for training and test data\n",
    "plot_confusion_matrix(y_train_adasyn, y_train_pred, 'Training Data Confusion Matrix', ax1)\n",
    "plot_confusion_matrix(y_test_nz, y_test_pred_nz, 'Test Data Confusion Matrix', ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "46230253030baee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#\n",
    "# from xgboost import XGBClassifier\n",
    "#\n",
    "#\n",
    "#\n",
    "# # Define models in a list of tuples (name, model instance)\n",
    "# models = [\n",
    "#     # ('SVM', SVC(kernel='rbf', C=0.5, gamma='scale', probability=True, random_state=42)),  # n_jobs not supported\n",
    "#     # ('KNN', KNeighborsClassifier(n_neighbors=8, metric='minkowski', p=2, n_jobs=-1)),\n",
    "#     # ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)),\n",
    "#     # ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
    "#     # ('Naive Bayes', GaussianNB()),  # no n_jobs\n",
    "#     ('XGBoost', XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', n_jobs=-1, random_state=42))\n",
    "# ]\n",
    "#\n",
    "#\n",
    "# def fit_and_evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "#     results = []\n",
    "#\n",
    "#     for i, (name, model) in enumerate(models):\n",
    "#         print(f\"\\nTraining {name}...\")\n",
    "#         model.fit(X_train, y_train - 1  )\n",
    "#\n",
    "#         y_train_pred = model.predict(X_train)\n",
    "#         y_test_pred = model.predict(X_test)\n",
    "#\n",
    "#         # Evaluation metrics\n",
    "#         train_acc = accuracy_score(y_train, y_train_pred)\n",
    "#         test_acc = accuracy_score(y_test, y_test_pred)\n",
    "#         train_bal_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "#         test_bal_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "#\n",
    "#         print(f\"{name} Training Accuracy: {train_acc:.4f}\")\n",
    "#         print(f\"{name} Training Balanced Accuracy: {train_bal_acc:.4f}\")\n",
    "#         print(f\"{name} Test Accuracy: {test_acc:.4f}\")\n",
    "#         print(f\"{name} Test Balanced Accuracy: {test_bal_acc:.4f}\")\n",
    "#\n",
    "#         results.append({\n",
    "#             'Model': name,\n",
    "#             'Train Accuracy': train_acc,\n",
    "#             'Train Balanced Accuracy': train_bal_acc,\n",
    "#             'Test Accuracy': test_acc,\n",
    "#             'Test Balanced Accuracy': test_bal_acc\n",
    "#         })\n",
    "#\n",
    "#         # Plot for this model\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "#         plot_confusion_matrix(y_train, y_train_pred, f'{name} - Train', axes[0])\n",
    "#         plot_confusion_matrix(y_test, y_test_pred, f'{name} - Test', axes[1])\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#\n",
    "#     return results\n",
    "#\n",
    "#\n",
    "# # X_train_selected = hard_spots_train_smoothed[feature_list]\n",
    "# # X_test_selected = hard_spots_test_smoothed[feature_list]\n",
    "# # y_train_nz = y_train_hard\n",
    "# # y_test_nz = y_test_hard\n",
    "# # X_train_adasyn, y_train_adasyn = X_train_selected, y_train_nz\n",
    "#\n",
    "# # Example call\n",
    "# results = fit_and_evaluate_models(models, X_train_adasyn, y_train_adasyn, X_test_selected, y_test_nz)\n",
    "#\n",
    "#\n",
    "# # Plot comparison bar chart\n",
    "# def plot_model_comparison(results):\n",
    "#     import pandas as pd\n",
    "#     import seaborn as sns\n",
    "#\n",
    "#     df = pd.DataFrame(results)\n",
    "#     df_melted = df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "#\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     sns.barplot(data=df_melted, x='Model', y='Score', hue='Metric')\n",
    "#     plt.title('Model Comparison')\n",
    "#     plt.ylim(0, 1.05)\n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#\n",
    "#\n",
    "# plot_model_comparison(results)\n"
   ],
   "id": "4bbde64cffef6a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8ede57e74fbe4ad4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
